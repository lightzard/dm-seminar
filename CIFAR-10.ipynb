{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#cifar-10\n",
    "\n",
    "#import autosklearn.classification\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from keras.datasets import mnist\n",
    "from keras.datasets import cifar10\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import openml as oml\n",
    "from keras.models import load_model\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "import openml as oml\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.utils import np_utils\n",
    "\n",
    "oml.config.apikey = 'b15b073c6fea6dc55b08f051f5e1abf9'\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16.0, 4.0) # Set default figure size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,505,610\n",
      "Trainable params: 1,505,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 511s 10ms/step - loss: 2.1501 - acc: 0.2082 - val_loss: 1.9956 - val_acc: 0.3051\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 509s 10ms/step - loss: 1.9975 - acc: 0.2708 - val_loss: 1.8744 - val_acc: 0.3315\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 509s 10ms/step - loss: 1.9308 - acc: 0.2968 - val_loss: 1.7551 - val_acc: 0.3761\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 510s 10ms/step - loss: 1.8776 - acc: 0.3164 - val_loss: 1.7349 - val_acc: 0.3896\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 669s 13ms/step - loss: 1.8300 - acc: 0.3323 - val_loss: 1.8653 - val_acc: 0.3249\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 690s 14ms/step - loss: 1.8077 - acc: 0.3407 - val_loss: 1.6852 - val_acc: 0.4122\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 876s 18ms/step - loss: 1.7776 - acc: 0.3537 - val_loss: 1.6849 - val_acc: 0.4019\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 804s 16ms/step - loss: 1.7637 - acc: 0.3576 - val_loss: 1.6690 - val_acc: 0.4143\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 845s 17ms/step - loss: 1.7420 - acc: 0.3629 - val_loss: 1.6381 - val_acc: 0.4183\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 893s 18ms/step - loss: 1.7255 - acc: 0.3749 - val_loss: 1.9742 - val_acc: 0.3477\n",
      "10000/10000 [==============================] - 56s 6ms/step\n",
      "Test score: 1.9742491958618165\n",
      "Test accuracy: 0.3477\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-60b1f24cee35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"vgglike_cifar10_10epoch.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#vgglike\n",
    "mean  = [125.307, 122.95, 113.865]\n",
    "std   = [62.9932, 62.0887, 66.7048]\n",
    "\n",
    "for i in range(3):\n",
    "    x_train[:,:,:,i] = (x_train[:,:,:,i] - mean[i]) / std[i]\n",
    "    x_test[:,:,:,i] = (x_test[:,:,:,i] - mean[i]) / std[i]\n",
    "\n",
    "# build network\n",
    "model3=Sequential()\n",
    "model3.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", \n",
    "          input_shape=x_train.shape[1:], activation='relu'))\n",
    "model3.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation='relu'))\n",
    "model3.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"valid\", activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(256))\n",
    "model3.add(LeakyReLU())\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(256))\n",
    "model3.add(LeakyReLU())\n",
    "#model2.add(Dropout(0.5))\n",
    "model3.add(Dense(10, activation='softmax'))\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "model3.summary()\n",
    "\n",
    "model3.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))\n",
    " \n",
    "score = model3.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    " \n",
    "model3.save(\"vgglike_cifar10_10epoch.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 10)\n",
      "Learning rate:  0.001\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 16)   0           activation_1[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 16)   0           activation_3[0][0]               \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 16)   2320        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 16)   0           activation_5[0][0]               \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 32)   4640        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 32)   544         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 32)   0           conv2d_14[0][0]                  \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 32)   0           activation_9[0][0]               \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 32)   9248        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 32)   128         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 32)   0           activation_11[0][0]              \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 64)     18496       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 64)     2112        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 64)     0           conv2d_21[0][0]                  \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 64)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 8, 64)     36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 64)     0           activation_15[0][0]              \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 8, 8, 64)     36928       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 64)     0           activation_17[0][0]              \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           650         flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 274,442\n",
      "Trainable params: 273,066\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n",
      "ResNet20v1\n",
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 1/10\n",
      "390/391 [============================>.] - ETA: 1s - loss: 1.5782 - acc: 0.4648Epoch 00001: val_acc improved from -inf to 0.46470, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v1_model.001.h5\n",
      "391/391 [==============================] - 719s 2s/step - loss: 1.5775 - acc: 0.4651 - val_loss: 1.7212 - val_acc: 0.4647\n",
      "Learning rate:  0.001\n",
      "Epoch 2/10\n",
      "390/391 [============================>.] - ETA: 1s - loss: 1.1853 - acc: 0.6182Epoch 00002: val_acc improved from 0.46470 to 0.47300, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v1_model.002.h5\n",
      "391/391 [==============================] - 715s 2s/step - loss: 1.1853 - acc: 0.6182 - val_loss: 1.6646 - val_acc: 0.4730\n",
      "Learning rate:  0.001\n",
      "Epoch 3/10\n",
      "390/391 [============================>.] - ETA: 1s - loss: 1.0105 - acc: 0.6854Epoch 00003: val_acc improved from 0.47300 to 0.60120, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v1_model.003.h5\n",
      "391/391 [==============================] - 716s 2s/step - loss: 1.0103 - acc: 0.6855 - val_loss: 1.3892 - val_acc: 0.6012\n",
      "Learning rate:  0.001\n",
      "Epoch 4/10\n",
      "390/391 [============================>.] - ETA: 1s - loss: 0.8935 - acc: 0.7276Epoch 00004: val_acc improved from 0.60120 to 0.72000, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v1_model.004.h5\n",
      "391/391 [==============================] - 715s 2s/step - loss: 0.8937 - acc: 0.7275 - val_loss: 0.9310 - val_acc: 0.7200\n",
      "Learning rate:  0.001\n",
      "Epoch 5/10\n",
      "390/391 [============================>.] - ETA: 1s - loss: 0.8096 - acc: 0.7589Epoch 00005: val_acc improved from 0.72000 to 0.73280, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v1_model.005.h5\n",
      "391/391 [==============================] - 715s 2s/step - loss: 0.8089 - acc: 0.7590 - val_loss: 0.9323 - val_acc: 0.7328\n",
      "Learning rate:  0.001\n",
      "Epoch 6/10\n",
      "390/391 [============================>.] - ETA: 1s - loss: 0.7546 - acc: 0.7791Epoch 00006: val_acc improved from 0.73280 to 0.75230, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v1_model.006.h5\n",
      "391/391 [==============================] - 715s 2s/step - loss: 0.7549 - acc: 0.7791 - val_loss: 0.8619 - val_acc: 0.7523\n",
      "Learning rate:  0.001\n",
      "Epoch 7/10\n",
      "390/391 [============================>.] - ETA: 1s - loss: 0.7079 - acc: 0.7963Epoch 00007: val_acc did not improve\n",
      "391/391 [==============================] - 721s 2s/step - loss: 0.7080 - acc: 0.7962 - val_loss: 0.8938 - val_acc: 0.7362\n",
      "Learning rate:  0.001\n",
      "Epoch 8/10\n",
      "390/391 [============================>.] - ETA: 1s - loss: 0.6690 - acc: 0.8120Epoch 00008: val_acc did not improve\n",
      "391/391 [==============================] - 729s 2s/step - loss: 0.6691 - acc: 0.8118 - val_loss: 0.8848 - val_acc: 0.7415\n",
      "Learning rate:  0.001\n",
      "Epoch 9/10\n",
      "390/391 [============================>.] - ETA: 1s - loss: 0.6446 - acc: 0.8201Epoch 00009: val_acc improved from 0.75230 to 0.75990, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v1_model.009.h5\n",
      "391/391 [==============================] - 730s 2s/step - loss: 0.6445 - acc: 0.8201 - val_loss: 0.8471 - val_acc: 0.7599\n",
      "Learning rate:  0.001\n",
      "Epoch 10/10\n",
      "390/391 [============================>.] - ETA: 1s - loss: 0.6164 - acc: 0.8306Epoch 00010: val_acc did not improve\n",
      "391/391 [==============================] - 729s 2s/step - loss: 0.6164 - acc: 0.8305 - val_loss: 0.8551 - val_acc: 0.7567\n",
      "10000/10000 [==============================] - 53s 5ms/step\n",
      "Test loss: 0.8551036379814148\n",
      "Test accuracy: 0.7567\n"
     ]
    }
   ],
   "source": [
    "#resnet https://github.com/keras-team/keras/blob/master/examples/cifar10_resnet.py\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
    "epochs = 10\n",
    "data_augmentation = True\n",
    "num_classes = 10\n",
    "\n",
    "# Subtracting pixel mean improves accuracy\n",
    "subtract_pixel_mean = True\n",
    "\n",
    "# Model parameter\n",
    "# ----------------------------------------------------------------------------\n",
    "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
    "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
    "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
    "# ----------------------------------------------------------------------------\n",
    "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
    "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
    "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
    "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
    "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
    "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
    "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
    "# ---------------------------------------------------------------------------\n",
    "n = 3\n",
    "\n",
    "# Model version\n",
    "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
    "version = 1\n",
    "\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "# Load the CIFAR10 data.\n",
    "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Normalize data.\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "#if subtract_pixel_mean:\n",
    "#    x_train_mean = np.mean(x_train, axis=0)\n",
    "#    x_train -= x_train_mean\n",
    "#    x_test -= x_train_mean\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def resnet_block(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            activation-bn-conv (False)\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = Conv2D(num_filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=strides,\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal',\n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation:\n",
    "            x = Activation(activation)(x)\n",
    "        return x\n",
    "    if batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = Activation('relu')(x)\n",
    "    x = Conv2D(num_filters,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=strides,\n",
    "               padding='same',\n",
    "               kernel_initializer='he_normal',\n",
    "               kernel_regularizer=l2(1e-4))(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    The number of filters doubles when the feature maps size\n",
    "    is halved.\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    inputs = Input(shape=input_shape)\n",
    "    num_filters = 16\n",
    "    num_sub_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    x = resnet_block(inputs=inputs)\n",
    "    # Instantiate convolutional base (stack of blocks).\n",
    "    for i in range(3):\n",
    "        for j in range(num_sub_blocks):\n",
    "            strides = 1\n",
    "            is_first_layer_but_not_first_block = j == 0 and i > 0\n",
    "            if is_first_layer_but_not_first_block:\n",
    "                strides = 2\n",
    "            y = resnet_block(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_block(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if is_first_layer_but_not_first_block:\n",
    "                x = resnet_block(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters = 2 * num_filters\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    Features maps sizes: 16(input), 64(1st sub_block), 128(2nd), 256(3rd)\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    inputs = Input(shape=input_shape)\n",
    "    num_filters_in = 16\n",
    "    num_filters_out = 64\n",
    "    filter_multiplier = 4\n",
    "    num_sub_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_block(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate convolutional base (stack of blocks).\n",
    "    activation = None\n",
    "    batch_normalization = False\n",
    "    for i in range(3):\n",
    "        if i > 0:\n",
    "            filter_multiplier = 2\n",
    "        num_filters_out = num_filters_in * filter_multiplier\n",
    "\n",
    "        for j in range(num_sub_blocks):\n",
    "            strides = 1\n",
    "            is_first_layer_but_not_first_block = j == 0 and i > 0\n",
    "            if is_first_layer_but_not_first_block:\n",
    "                strides = 2\n",
    "            y = resnet_block(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            y = resnet_block(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_block(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if j == 0:\n",
    "                x = resnet_block(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "if version == 2:\n",
    "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "else:\n",
    "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(model_type)\n",
    "\n",
    "# Prepare model model saving directory.\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=10, verbose=1, workers=-1,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"resnet20v1_cifar10_10epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 14, 14, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,505,610\n",
      "Trainable params: 1,505,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 509s 10ms/step - loss: 2.2143 - acc: 0.1830 - val_loss: 2.0319 - val_acc: 0.3003\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 505s 10ms/step - loss: 1.9947 - acc: 0.2743 - val_loss: 1.7764 - val_acc: 0.3690\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 506s 10ms/step - loss: 1.8688 - acc: 0.3174 - val_loss: 1.7156 - val_acc: 0.3880\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 505s 10ms/step - loss: 1.8080 - acc: 0.3363 - val_loss: 1.6943 - val_acc: 0.4107\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 506s 10ms/step - loss: 1.7846 - acc: 0.3441 - val_loss: 1.6420 - val_acc: 0.4248\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 519s 10ms/step - loss: 1.7689 - acc: 0.3518 - val_loss: 1.8266 - val_acc: 0.3603\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 747s 15ms/step - loss: 1.7422 - acc: 0.3619 - val_loss: 1.5914 - val_acc: 0.4454\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 805s 16ms/step - loss: 1.7315 - acc: 0.3631 - val_loss: 1.5678 - val_acc: 0.4371\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 855s 17ms/step - loss: 1.7315 - acc: 0.3621 - val_loss: 1.6157 - val_acc: 0.4274\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 767s 15ms/step - loss: 1.7203 - acc: 0.3703 - val_loss: 1.6539 - val_acc: 0.4075\n",
      "10000/10000 [==============================] - 38s 4ms/step\n",
      "Test score: 1.6539471603393554\n",
      "Test accuracy: 0.4075\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#vgg-like\n",
    "\n",
    "model3=Sequential()\n",
    "model3.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", \n",
    "          input_shape=x_train.shape[1:], activation='relu'))\n",
    "model3.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation='relu'))\n",
    "model3.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"valid\", activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(256))\n",
    "model3.add(LeakyReLU())\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(256))\n",
    "model3.add(LeakyReLU())\n",
    "#model2.add(Dropout(0.5))\n",
    "model3.add(Dense(10, activation='softmax'))\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "model3.summary()\n",
    "\n",
    "model3.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))\n",
    " \n",
    "score = model3.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    " \n",
    "model3.save(\"vgglike_cifar10_10epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 10)\n",
      "Learning rate:  0.001\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   272         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 64)   1088        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 64)   1088        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 64)   0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   1040        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 64)   1088        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 64)   0           add_1[0][0]                      \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 64)   4160        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 128)  8320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 128)  8320        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 128)  0           conv2d_12[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 64)   8256        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 64)   36928       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 128)  8320        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 128)  0           add_3[0][0]                      \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 128)  512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 128)    16512       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 128)    512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 128)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 128)    147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 128)    512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 128)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 256)    33024       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 8, 256)    33024       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 256)    0           conv2d_19[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 256)    1024        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 256)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 128)    32896       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 128)    512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 128)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 128)    147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 128)    512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 128)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 8, 8, 256)    33024       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 256)    0           add_5[0][0]                      \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 256)    1024        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 256)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 256)    0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 256)          0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           2570        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 574,090\n",
      "Trainable params: 570,602\n",
      "Non-trainable params: 3,488\n",
      "__________________________________________________________________________________________________\n",
      "ResNet20v2\n",
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 1/10\n",
      "390/391 [============================>.] - ETA: 2s - loss: 1.7089 - acc: 0.4892Epoch 00001: val_acc improved from -inf to 0.52670, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v2_model.001.h5\n",
      "391/391 [==============================] - 1206s 3s/step - loss: 1.7078 - acc: 0.4896 - val_loss: 1.5792 - val_acc: 0.5267\n",
      "Learning rate:  0.001\n",
      "Epoch 2/10\n",
      "390/391 [============================>.] - ETA: 2s - loss: 1.3024 - acc: 0.6329Epoch 00002: val_acc improved from 0.52670 to 0.63180, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v2_model.002.h5\n",
      "391/391 [==============================] - 1203s 3s/step - loss: 1.3020 - acc: 0.6330 - val_loss: 1.2993 - val_acc: 0.6318\n",
      "Learning rate:  0.001\n",
      "Epoch 3/10\n",
      "390/391 [============================>.] - ETA: 2s - loss: 1.1408 - acc: 0.6855Epoch 00003: val_acc improved from 0.63180 to 0.65400, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v2_model.003.h5\n",
      "391/391 [==============================] - 1193s 3s/step - loss: 1.1404 - acc: 0.6856 - val_loss: 1.2448 - val_acc: 0.6540\n",
      "Learning rate:  0.001\n",
      "Epoch 4/10\n",
      "390/391 [============================>.] - ETA: 2s - loss: 1.0240 - acc: 0.7229Epoch 00004: val_acc did not improve\n",
      "391/391 [==============================] - 1193s 3s/step - loss: 1.0244 - acc: 0.7227 - val_loss: 1.8345 - val_acc: 0.5488\n",
      "Learning rate:  0.001\n",
      "Epoch 5/10\n",
      "390/391 [============================>.] - ETA: 2s - loss: 0.9418 - acc: 0.7498Epoch 00005: val_acc improved from 0.65400 to 0.66970, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v2_model.005.h5\n",
      "391/391 [==============================] - 1193s 3s/step - loss: 0.9418 - acc: 0.7496 - val_loss: 1.2508 - val_acc: 0.6697\n",
      "Learning rate:  0.001\n",
      "Epoch 6/10\n",
      "390/391 [============================>.] - ETA: 2s - loss: 0.8787 - acc: 0.7716Epoch 00006: val_acc improved from 0.66970 to 0.75890, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v2_model.006.h5\n",
      "391/391 [==============================] - 1194s 3s/step - loss: 0.8784 - acc: 0.7717 - val_loss: 0.9169 - val_acc: 0.7589\n",
      "Learning rate:  0.001\n",
      "Epoch 7/10\n",
      "390/391 [============================>.] - ETA: 2s - loss: 0.8280 - acc: 0.7892Epoch 00007: val_acc did not improve\n",
      "391/391 [==============================] - 1204s 3s/step - loss: 0.8278 - acc: 0.7893 - val_loss: 0.9540 - val_acc: 0.7449\n",
      "Learning rate:  0.001\n",
      "Epoch 8/10\n",
      "390/391 [============================>.] - ETA: 2s - loss: 0.7929 - acc: 0.8000Epoch 00008: val_acc improved from 0.75890 to 0.76440, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v2_model.008.h5\n",
      "391/391 [==============================] - 1202s 3s/step - loss: 0.7933 - acc: 0.8001 - val_loss: 0.9010 - val_acc: 0.7644\n",
      "Learning rate:  0.001\n",
      "Epoch 9/10\n",
      "390/391 [============================>.] - ETA: 2s - loss: 0.7562 - acc: 0.8114Epoch 00009: val_acc did not improve\n",
      "391/391 [==============================] - 1203s 3s/step - loss: 0.7561 - acc: 0.8114 - val_loss: 0.9520 - val_acc: 0.7585\n",
      "Learning rate:  0.001\n",
      "Epoch 10/10\n",
      "390/391 [============================>.] - ETA: 2s - loss: 0.7313 - acc: 0.8182Epoch 00010: val_acc did not improve\n",
      "391/391 [==============================] - 1198s 3s/step - loss: 0.7316 - acc: 0.8181 - val_loss: 1.2436 - val_acc: 0.6790\n",
      "10000/10000 [==============================] - 90s 9ms/step\n",
      "Test loss: 1.243637539100647\n",
      "Test accuracy: 0.679\n"
     ]
    }
   ],
   "source": [
    "#resnet https://github.com/keras-team/keras/blob/master/examples/cifar10_resnet.py\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
    "epochs = 10\n",
    "data_augmentation = True\n",
    "num_classes = 10\n",
    "\n",
    "# Subtracting pixel mean improves accuracy\n",
    "subtract_pixel_mean = True\n",
    "\n",
    "# Model parameter\n",
    "# ----------------------------------------------------------------------------\n",
    "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
    "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
    "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
    "# ----------------------------------------------------------------------------\n",
    "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
    "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
    "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
    "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
    "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
    "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
    "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
    "# ---------------------------------------------------------------------------\n",
    "n = 2\n",
    "\n",
    "# Model version\n",
    "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
    "version = 2\n",
    "\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "# Load the CIFAR10 data.\n",
    "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Normalize data.\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "#if subtract_pixel_mean:\n",
    "#    x_train_mean = np.mean(x_train, axis=0)\n",
    "#    x_train -= x_train_mean\n",
    "#    x_test -= x_train_mean\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def resnet_block(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            activation-bn-conv (False)\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = Conv2D(num_filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=strides,\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal',\n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation:\n",
    "            x = Activation(activation)(x)\n",
    "        return x\n",
    "    if batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = Activation('relu')(x)\n",
    "    x = Conv2D(num_filters,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=strides,\n",
    "               padding='same',\n",
    "               kernel_initializer='he_normal',\n",
    "               kernel_regularizer=l2(1e-4))(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    The number of filters doubles when the feature maps size\n",
    "    is halved.\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    inputs = Input(shape=input_shape)\n",
    "    num_filters = 16\n",
    "    num_sub_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    x = resnet_block(inputs=inputs)\n",
    "    # Instantiate convolutional base (stack of blocks).\n",
    "    for i in range(3):\n",
    "        for j in range(num_sub_blocks):\n",
    "            strides = 1\n",
    "            is_first_layer_but_not_first_block = j == 0 and i > 0\n",
    "            if is_first_layer_but_not_first_block:\n",
    "                strides = 2\n",
    "            y = resnet_block(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_block(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if is_first_layer_but_not_first_block:\n",
    "                x = resnet_block(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters = 2 * num_filters\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    Features maps sizes: 16(input), 64(1st sub_block), 128(2nd), 256(3rd)\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    inputs = Input(shape=input_shape)\n",
    "    num_filters_in = 16\n",
    "    num_filters_out = 64\n",
    "    filter_multiplier = 4\n",
    "    num_sub_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_block(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate convolutional base (stack of blocks).\n",
    "    activation = None\n",
    "    batch_normalization = False\n",
    "    for i in range(3):\n",
    "        if i > 0:\n",
    "            filter_multiplier = 2\n",
    "        num_filters_out = num_filters_in * filter_multiplier\n",
    "\n",
    "        for j in range(num_sub_blocks):\n",
    "            strides = 1\n",
    "            is_first_layer_but_not_first_block = j == 0 and i > 0\n",
    "            if is_first_layer_but_not_first_block:\n",
    "                strides = 2\n",
    "            y = resnet_block(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            y = resnet_block(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_block(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if j == 0:\n",
    "                x = resnet_block(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "if version == 2:\n",
    "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "else:\n",
    "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(model_type)\n",
    "\n",
    "# Prepare model model saving directory.\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=10, verbose=1, workers=-1,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "model.save(\"resnet20v2_cifar10_10epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (3, 3), activation=\"relu\", strides=(2, 2), padding=\"valid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "  app.launch_new_instance()\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\legacy\\layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:42: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:46: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:49: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:53: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:54: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:55: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:56: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:61: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:63: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:70: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:71: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:72: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:73: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:78: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), padding=\"valid\", kernel_initializer=\"glorot_uniform\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:81: UserWarning: Update your `AveragePooling2D` call to the Keras 2 API: `AveragePooling2D((13, 13), strides=(1, 1), padding=\"same\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:87: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 15, 15, 96)   2688        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 7, 7, 96)     0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 16)     1552        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 64)     1088        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 64)     9280        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "merge_9 (Merge)                 (None, 14, 7, 64)    0           conv2d_50[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 7, 64)    0           merge_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 14, 7, 16)    1040        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 14, 7, 64)    1088        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 14, 7, 64)    9280        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "merge_10 (Merge)                (None, 28, 7, 64)    0           conv2d_53[0][0]                  \n",
      "                                                                 conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 28, 7, 64)    0           merge_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 28, 7, 32)    2080        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 28, 7, 128)   4224        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 28, 7, 128)   36992       conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "merge_11 (Merge)                (None, 56, 7, 128)   0           conv2d_56[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 56, 7, 128)   0           merge_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 28, 3, 128)   0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 28, 3, 32)    4128        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 28, 3, 128)   4224        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 28, 3, 128)   36992       conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "merge_12 (Merge)                (None, 56, 3, 128)   0           conv2d_59[0][0]                  \n",
      "                                                                 conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 56, 3, 128)   0           merge_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 56, 3, 48)    6192        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 56, 3, 192)   9408        conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 56, 3, 192)   83136       conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "merge_13 (Merge)                (None, 112, 3, 192)  0           conv2d_62[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 112, 3, 192)  0           merge_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 112, 3, 48)   9264        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 112, 3, 192)  9408        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 112, 3, 192)  83136       conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "merge_14 (Merge)                (None, 224, 3, 192)  0           conv2d_65[0][0]                  \n",
      "                                                                 conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 224, 3, 192)  0           merge_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 224, 3, 64)   12352       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 224, 3, 256)  16640       conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 224, 3, 256)  147712      conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "merge_15 (Merge)                (None, 448, 3, 256)  0           conv2d_68[0][0]                  \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 448, 3, 256)  0           merge_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 224, 1, 256)  0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 224, 1, 64)   16448       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 224, 1, 256)  16640       conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 224, 1, 256)  147712      conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "merge_16 (Merge)                (None, 448, 1, 256)  0           conv2d_71[0][0]                  \n",
      "                                                                 conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 448, 1, 256)  0           merge_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 448, 1, 256)  0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 448, 1, 10)   2570        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 448, 1, 10)   0           conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 4480)         0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           44810       flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 720,084\n",
      "Trainable params: 720,084\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 1363s 27ms/step - loss: 2.1392 - acc: 0.1918 - val_loss: 1.9244 - val_acc: 0.2775\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 1356s 27ms/step - loss: 1.8131 - acc: 0.3271 - val_loss: 1.7618 - val_acc: 0.3615\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 1352s 27ms/step - loss: 1.6038 - acc: 0.4135 - val_loss: 1.5000 - val_acc: 0.4519\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 1354s 27ms/step - loss: 1.4638 - acc: 0.4740 - val_loss: 1.5478 - val_acc: 0.4406\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 1347s 27ms/step - loss: 1.3638 - acc: 0.5121 - val_loss: 1.3348 - val_acc: 0.5162\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 1349s 27ms/step - loss: 1.2902 - acc: 0.5409 - val_loss: 1.3048 - val_acc: 0.5412\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 1347s 27ms/step - loss: 1.2245 - acc: 0.5629 - val_loss: 1.2405 - val_acc: 0.5590\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 1358s 27ms/step - loss: 1.1717 - acc: 0.5864 - val_loss: 1.1960 - val_acc: 0.5749\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 1355s 27ms/step - loss: 1.1282 - acc: 0.6006 - val_loss: 1.1945 - val_acc: 0.5725\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 1358s 27ms/step - loss: 1.0826 - acc: 0.6174 - val_loss: 1.2464 - val_acc: 0.5550\n",
      "10000/10000 [==============================] - 83s 8ms/step\n",
      "Test score: 1.246408338546753\n",
      "Test accuracy: 0.555\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, merge\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "input_layer = Input(shape=(32, 32,3), name=\"input\")\n",
    "\n",
    "#conv 1\n",
    "conv1 = Convolution2D(96, 3, 3, activation='relu', init='glorot_uniform',subsample=(2,2),border_mode='valid')(input_layer)\n",
    "\n",
    "#maxpool 1\n",
    "maxpool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "\n",
    "#fire 1\n",
    "fire2_squeeze = Convolution2D(16, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(maxpool1)\n",
    "fire2_expand1 = Convolution2D(64, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire2_squeeze)\n",
    "fire2_expand2 = Convolution2D(64, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire2_squeeze)\n",
    "merge1 = merge(inputs=[fire2_expand1, fire2_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire2 = Activation(\"linear\")(merge1)\n",
    "\n",
    "#fire 2\n",
    "fire3_squeeze = Convolution2D(16, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire2)\n",
    "fire3_expand1 = Convolution2D(64, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire3_squeeze)\n",
    "fire3_expand2 = Convolution2D(64, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire3_squeeze)\n",
    "merge2 = merge(inputs=[fire3_expand1, fire3_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire3 = Activation(\"linear\")(merge2)\n",
    "\n",
    "#fire 3\n",
    "fire4_squeeze = Convolution2D(32, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire3)\n",
    "fire4_expand1 = Convolution2D(128, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire4_squeeze)\n",
    "fire4_expand2 = Convolution2D(128, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire4_squeeze)\n",
    "merge3 = merge(inputs=[fire4_expand1, fire4_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire4 = Activation(\"linear\")(merge3)\n",
    "\n",
    "#maxpool 4\n",
    "maxpool4 = MaxPooling2D((2,2))(fire4)\n",
    "\n",
    "#fire 5\n",
    "fire5_squeeze = Convolution2D(32, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(maxpool4)\n",
    "fire5_expand1 = Convolution2D(128, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire5_squeeze)\n",
    "fire5_expand2 = Convolution2D(128, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire5_squeeze)\n",
    "merge5 = merge(inputs=[fire5_expand1, fire5_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire5 = Activation(\"linear\")(merge5)\n",
    "\n",
    "#fire 6\n",
    "fire6_squeeze = Convolution2D(48, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire5)\n",
    "fire6_expand1 = Convolution2D(192, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire6_squeeze)\n",
    "fire6_expand2 = Convolution2D(192, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire6_squeeze)\n",
    "merge6 = merge(inputs=[fire6_expand1, fire6_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire6 = Activation(\"linear\")(merge6)\n",
    "\n",
    "#fire 7\n",
    "fire7_squeeze = Convolution2D(48, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire6)\n",
    "fire7_expand1 = Convolution2D(192, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire7_squeeze)\n",
    "fire7_expand2 = Convolution2D(192, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire7_squeeze)\n",
    "merge7 = merge(inputs=[fire7_expand1, fire7_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire7 =Activation(\"linear\")(merge7)\n",
    "\n",
    "#fire 8\n",
    "fire8_squeeze = Convolution2D(64, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire7)\n",
    "fire8_expand1 = Convolution2D(256, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire8_squeeze)\n",
    "fire8_expand2 = Convolution2D(256, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire8_squeeze)\n",
    "merge8 = merge(inputs=[fire8_expand1, fire8_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire8 = Activation(\"linear\")(merge8)\n",
    "\n",
    "#maxpool 8\n",
    "maxpool8 = MaxPooling2D((2,2))(fire8)\n",
    "\n",
    "#fire 9\n",
    "fire9_squeeze = Convolution2D(64, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(maxpool8)\n",
    "fire9_expand1 = Convolution2D(256, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire9_squeeze)\n",
    "fire9_expand2 = Convolution2D(256, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire9_squeeze)\n",
    "merge8 = merge(inputs=[fire9_expand1, fire9_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire9 = Activation(\"linear\")(merge8)\n",
    "fire9_dropout = Dropout(0.5)(fire9)\n",
    "\n",
    "#conv 10\n",
    "conv10 = Convolution2D(10, 1, 1, init='glorot_uniform',border_mode='valid')(fire9_dropout)\n",
    "\n",
    "#avgpool 1\n",
    "avgpool10 = AveragePooling2D((13,13), strides=(1,1), border_mode='same')(conv10)\n",
    "\n",
    "flatten = Flatten()(avgpool10)\n",
    "\n",
    "softmax = Dense(10, activation=\"softmax\")(flatten)\n",
    "\n",
    "model = Model(input=input_layer, output=softmax)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adadelta', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))\n",
    " \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    " \n",
    "model.save(\"squeezenet_cifar10_10epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
