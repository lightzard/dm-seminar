{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#fashion MNIST\n",
    "\n",
    "#import autosklearn.classification\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from keras.datasets import mnist\n",
    "from keras.datasets import cifar10\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import openml as oml\n",
    "from keras.models import load_model\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "import openml as oml\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.utils import np_utils\n",
    "\n",
    "oml.config.apikey = 'b15b073c6fea6dc55b08f051f5e1abf9'\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16.0, 4.0) # Set default figure size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n",
      "y_train shape: (60000,)\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "y_train shape: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train2, y_train2), (x_test2, y_test2) = fashion_mnist.load_data()\n",
    "print(\"x_train shape: {}\".format(x_train2.shape))\n",
    "print(\"y_train shape: {}\".format(y_train2.shape))\n",
    "x_train2 = x_train2.reshape(x_train2.shape[0], 28, 28, 1)\n",
    "x_test2 = x_test2.reshape(x_test2.shape[0], 28, 28, 1)\n",
    " \n",
    "y_train2 = np_utils.to_categorical(y_train2, 10)\n",
    "y_test2 = np_utils.to_categorical(y_test2, 10)\n",
    " \n",
    "print(\"x_train shape: {}\".format(x_train2.shape))\n",
    "print(\"y_train shape: {}\".format(y_train2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,505,034\n",
      "Trainable params: 1,505,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 610s 10ms/step - loss: 1.8901 - acc: 0.6707 - val_loss: 0.4249 - val_acc: 0.8463\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 649s 11ms/step - loss: 0.4661 - acc: 0.8300 - val_loss: 0.3522 - val_acc: 0.8742\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 648s 11ms/step - loss: 0.4017 - acc: 0.8531 - val_loss: 0.3225 - val_acc: 0.8833\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 554s 9ms/step - loss: 0.3615 - acc: 0.8680 - val_loss: 0.3100 - val_acc: 0.8837\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 436s 7ms/step - loss: 0.3337 - acc: 0.8786 - val_loss: 0.3122 - val_acc: 0.8827\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 436s 7ms/step - loss: 0.3161 - acc: 0.8852 - val_loss: 0.2776 - val_acc: 0.8961\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 439s 7ms/step - loss: 0.3009 - acc: 0.8913 - val_loss: 0.2723 - val_acc: 0.9005\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 439s 7ms/step - loss: 0.2870 - acc: 0.8944 - val_loss: 0.2683 - val_acc: 0.8988\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 433s 7ms/step - loss: 0.2795 - acc: 0.8970 - val_loss: 0.2545 - val_acc: 0.9078\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 435s 7ms/step - loss: 0.2679 - acc: 0.9030 - val_loss: 0.2446 - val_acc: 0.9120\n",
      "10000/10000 [==============================] - 24s 2ms/step\n",
      "Test score: 0.24461981319189072\n",
      "Test accuracy: 0.912\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#vgg-like\n",
    "\n",
    "model3=Sequential()\n",
    "model3.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", \n",
    "          input_shape=x_train2.shape[1:], activation='relu'))\n",
    "model3.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation='relu'))\n",
    "model3.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"valid\", activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(256))\n",
    "model3.add(LeakyReLU())\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(256))\n",
    "model3.add(LeakyReLU())\n",
    "#model2.add(Dropout(0.5))\n",
    "model3.add(Dense(10, activation='softmax'))\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "model3.summary()\n",
    "\n",
    "model3.fit(x_train2, y_train2, batch_size=128, epochs=10, validation_data=(x_test2, y_test2))\n",
    " \n",
    "score = model3.evaluate(x_test2, y_test2, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    " \n",
    "model3.save(\"vgglike_fashinmnist_30epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train2 shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (60000, 10)\n",
      "Learning rate:  0.001\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 32, 32, 1)    0           input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 32, 32, 16)   160         zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 32, 32, 16)   2320        conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 32, 32, 16)   64          conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 32, 32, 16)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 32, 32, 16)   2320        activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 32, 32, 16)   64          conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_102 (Add)                   (None, 32, 32, 16)   0           conv2d_236[0][0]                 \n",
      "                                                                 batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 32, 32, 16)   0           add_102[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 32, 32, 16)   2320        activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 32, 32, 16)   64          conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 32, 32, 16)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 32, 32, 16)   2320        activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 32, 32, 16)   64          conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_103 (Add)                   (None, 32, 32, 16)   0           activation_210[0][0]             \n",
      "                                                                 batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 32, 32, 16)   0           add_103[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 32, 32, 16)   2320        activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 32, 32, 16)   64          conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 32, 32, 16)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 32, 32, 16)   2320        activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 32, 32, 16)   64          conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_104 (Add)                   (None, 32, 32, 16)   0           activation_212[0][0]             \n",
      "                                                                 batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 32, 32, 16)   0           add_104[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 16, 16, 32)   4640        activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 16, 16, 32)   128         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 16, 16, 32)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 16, 16, 32)   9248        activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 16, 16, 32)   544         activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 16, 16, 32)   128         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_105 (Add)                   (None, 16, 16, 32)   0           conv2d_245[0][0]                 \n",
      "                                                                 batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 16, 16, 32)   0           add_105[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 16, 16, 32)   9248        activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 16, 16, 32)   128         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 16, 16, 32)   0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 16, 16, 32)   9248        activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 16, 16, 32)   128         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_106 (Add)                   (None, 16, 16, 32)   0           activation_216[0][0]             \n",
      "                                                                 batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 16, 16, 32)   0           add_106[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 16, 16, 32)   9248        activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 16, 16, 32)   128         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 16, 16, 32)   0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 16, 16, 32)   9248        activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 16, 16, 32)   128         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_107 (Add)                   (None, 16, 16, 32)   0           activation_218[0][0]             \n",
      "                                                                 batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 16, 16, 32)   0           add_107[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 8, 8, 64)     18496       activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 8, 8, 64)     256         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 8, 8, 64)     0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 8, 8, 64)     36928       activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 8, 8, 64)     2112        activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 8, 8, 64)     256         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_108 (Add)                   (None, 8, 8, 64)     0           conv2d_252[0][0]                 \n",
      "                                                                 batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 8, 8, 64)     0           add_108[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 8, 8, 64)     36928       activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 8, 8, 64)     256         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 8, 8, 64)     0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 8, 8, 64)     36928       activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 8, 8, 64)     256         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_109 (Add)                   (None, 8, 8, 64)     0           activation_222[0][0]             \n",
      "                                                                 batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 8, 8, 64)     0           add_109[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 8, 8, 64)     36928       activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 8, 8, 64)     256         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 8, 8, 64)     0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 8, 8, 64)     36928       activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 8, 8, 64)     256         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_110 (Add)                   (None, 8, 8, 64)     0           activation_224[0][0]             \n",
      "                                                                 batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 8, 8, 64)     0           add_110[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 1, 1, 64)     0           activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 64)           0           average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 10)           650         flatten_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 274,090\n",
      "Trainable params: 272,746\n",
      "Non-trainable params: 1,344\n",
      "__________________________________________________________________________________________________\n",
      "ResNet20v1\n",
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 1/10\n",
      "468/469 [============================>.] - ETA: 1s - loss: 9.1455 - acc: 0.3500Epoch 00001: val_acc improved from -inf to 0.48630, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v1_model.001.h5\n",
      "469/469 [==============================] - 835s 2s/step - loss: 9.1414 - acc: 0.3503 - val_loss: 6.8819 - val_acc: 0.4863\n",
      "Learning rate:  0.001\n",
      "Epoch 2/10\n",
      "468/469 [============================>.] - ETA: 1s - loss: 5.8133 - acc: 0.5467Epoch 00002: val_acc improved from 0.48630 to 0.50730, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v1_model.002.h5\n",
      "469/469 [==============================] - 794s 2s/step - loss: 5.8108 - acc: 0.5470 - val_loss: 5.4906 - val_acc: 0.5073\n",
      "Learning rate:  0.001\n",
      "Epoch 3/10\n",
      "468/469 [============================>.] - ETA: 1s - loss: 5.2038 - acc: 0.5957Epoch 00003: val_acc did not improve\n",
      "469/469 [==============================] - 786s 2s/step - loss: 5.2065 - acc: 0.5955 - val_loss: 5.5779 - val_acc: 0.4762\n",
      "Learning rate:  0.001\n",
      "Epoch 4/10\n",
      "468/469 [============================>.] - ETA: 1s - loss: 5.1657 - acc: 0.6064Epoch 00004: val_acc improved from 0.50730 to 0.59590, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v1_model.004.h5\n",
      "469/469 [==============================] - 786s 2s/step - loss: 5.1654 - acc: 0.6064 - val_loss: 5.2081 - val_acc: 0.5959\n",
      "Learning rate:  0.001\n",
      "Epoch 5/10\n",
      "468/469 [============================>.] - ETA: 1s - loss: 5.1349 - acc: 0.6156Epoch 00005: val_acc did not improve\n",
      "469/469 [==============================] - 782s 2s/step - loss: 5.1346 - acc: 0.6156 - val_loss: 5.3784 - val_acc: 0.5486\n",
      "Learning rate:  0.001\n",
      "Epoch 6/10\n",
      "468/469 [============================>.] - ETA: 1s - loss: 5.1173 - acc: 0.6200Epoch 00006: val_acc improved from 0.59590 to 0.59710, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v1_model.006.h5\n",
      "469/469 [==============================] - 782s 2s/step - loss: 5.1154 - acc: 0.6201 - val_loss: 5.1906 - val_acc: 0.5971\n",
      "Learning rate:  0.001\n",
      "Epoch 7/10\n",
      "468/469 [============================>.] - ETA: 1s - loss: 5.0996 - acc: 0.6235Epoch 00007: val_acc improved from 0.59710 to 0.61110, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v1_model.007.h5\n",
      "469/469 [==============================] - 786s 2s/step - loss: 5.1002 - acc: 0.6235 - val_loss: 5.1481 - val_acc: 0.6111\n",
      "Learning rate:  0.001\n",
      "Epoch 8/10\n",
      "468/469 [============================>.] - ETA: 1s - loss: 5.0870 - acc: 0.6283Epoch 00008: val_acc did not improve\n",
      "469/469 [==============================] - 786s 2s/step - loss: 5.0843 - acc: 0.6284 - val_loss: 5.2066 - val_acc: 0.5931\n",
      "Learning rate:  0.001\n",
      "Epoch 9/10\n",
      "468/469 [============================>.] - ETA: 1s - loss: 5.0756 - acc: 0.6302Epoch 00009: val_acc did not improve\n",
      "469/469 [==============================] - 786s 2s/step - loss: 5.0758 - acc: 0.6303 - val_loss: 5.3467 - val_acc: 0.5562\n",
      "Learning rate:  0.001\n",
      "Epoch 10/10\n",
      "468/469 [============================>.] - ETA: 1s - loss: 5.0654 - acc: 0.6333Epoch 00010: val_acc did not improve\n",
      "469/469 [==============================] - 786s 2s/step - loss: 5.0659 - acc: 0.6333 - val_loss: 5.1770 - val_acc: 0.5920\n",
      "10000/10000 [==============================] - 49s 5ms/step\n",
      "Test loss: 5.177034275054932\n",
      "Test accuracy: 0.592\n"
     ]
    }
   ],
   "source": [
    "#resnet https://github.com/keras-team/keras/blob/master/examples/cifar10_resnet.py\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
    "epochs = 10\n",
    "data_augmentation = True\n",
    "num_classes = 10\n",
    "\n",
    "# Subtracting pixel mean improves accuracy\n",
    "subtract_pixel_mean = True\n",
    "\n",
    "# Model parameter\n",
    "# ----------------------------------------------------------------------------\n",
    "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
    "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
    "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
    "# ----------------------------------------------------------------------------\n",
    "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
    "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
    "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
    "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
    "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
    "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
    "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
    "# ---------------------------------------------------------------------------\n",
    "n = 3\n",
    "\n",
    "# Model version\n",
    "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
    "version = 1\n",
    "\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "# Load the CIFAR10 data.\n",
    "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Input image dimensions.\n",
    "input_shape = (28,28,1)#x_train2.shape[1:]\n",
    "\n",
    "# Normalize data.\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "#if subtract_pixel_mean:\n",
    "#    x_train_mean = np.mean(x_train, axis=0)\n",
    "#    x_train -= x_train_mean\n",
    "#    x_test -= x_train_mean\n",
    "\n",
    "print('x_train2 shape:', x_train2.shape)\n",
    "print(x_train2.shape[0], 'train samples')\n",
    "print(x_test2.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train2.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "def resnet_first_block(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            activation-bn-conv (False)\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    x = ZeroPadding2D(padding=(2, 2), data_format=None)(inputs)\n",
    "    \n",
    "    y = Conv2D(num_filters,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=strides,\n",
    "               padding='same',\n",
    "               kernel_initializer='he_normal',\n",
    "               kernel_regularizer=l2(1e-4))(x)\n",
    "    \n",
    "    return y\n",
    "\n",
    "def resnet_block(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            activation-bn-conv (False)\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = Conv2D(num_filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=strides,\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal',\n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation:\n",
    "            x = Activation(activation)(x)\n",
    "        return x\n",
    "    if batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = Activation('relu')(x)\n",
    "    x = Conv2D(num_filters,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=strides,\n",
    "               padding='same',\n",
    "               kernel_initializer='he_normal',\n",
    "               kernel_regularizer=l2(1e-4))(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    The number of filters doubles when the feature maps size\n",
    "    is halved.\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    inputs = Input(shape=input_shape)\n",
    "    num_filters = 16\n",
    "    num_sub_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    x = resnet_first_block(inputs=inputs)\n",
    "    # Instantiate convolutional base (stack of blocks).\n",
    "    for i in range(3):\n",
    "        for j in range(num_sub_blocks):\n",
    "            strides = 1\n",
    "            is_first_layer_but_not_first_block = j == 0 and i > 0\n",
    "            if is_first_layer_but_not_first_block:\n",
    "                strides = 2\n",
    "            y = resnet_block(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_block(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if is_first_layer_but_not_first_block:\n",
    "                x = resnet_block(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters = 2 * num_filters\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    Features maps sizes: 16(input), 64(1st sub_block), 128(2nd), 256(3rd)\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    inputs = Input(shape=input_shape)\n",
    "    num_filters_in = 16\n",
    "    num_filters_out = 64\n",
    "    filter_multiplier = 4\n",
    "    num_sub_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_block(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate convolutional base (stack of blocks).\n",
    "    activation = None\n",
    "    batch_normalization = False\n",
    "    for i in range(3):\n",
    "        if i > 0:\n",
    "            filter_multiplier = 2\n",
    "        num_filters_out = num_filters_in * filter_multiplier\n",
    "\n",
    "        for j in range(num_sub_blocks):\n",
    "            strides = 1\n",
    "            is_first_layer_but_not_first_block = j == 0 and i > 0\n",
    "            if is_first_layer_but_not_first_block:\n",
    "                strides = 2\n",
    "            y = resnet_block(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            y = resnet_block(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_block(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if j == 0:\n",
    "                x = resnet_block(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "if version == 2:\n",
    "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "else:\n",
    "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(model_type)\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "# Prepare model model saving directory.\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train2, y_train2,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test2, y_test2),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train2)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train2, y_train2, batch_size=128),\n",
    "                        validation_data=(x_test2, y_test2),\n",
    "                        epochs=10, verbose=1, workers=-1,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test2, y_test2, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "model.save(\"resnet20v1_fashionmnist_10epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train2.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autosklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-bb85952a9dd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mautosklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'autosklearn'"
     ]
    }
   ],
   "source": [
    "import autosklearn.classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train2 shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (60000, 10)\n",
      "Learning rate:  0.001\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 32, 32, 1)    0           input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 32, 32, 16)   160         zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 32, 32, 16)   272         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 32, 32, 16)   64          conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 32, 32, 16)   0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 32, 32, 16)   2320        activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 32, 32, 16)   64          conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 32, 32, 16)   0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 32, 32, 64)   1088        conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 32, 32, 64)   1088        activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_111 (Add)                   (None, 32, 32, 64)   0           conv2d_261[0][0]                 \n",
      "                                                                 conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 32, 32, 64)   256         add_111[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 32, 32, 64)   0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 32, 32, 16)   1040        activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 32, 32, 16)   64          conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 32, 32, 16)   0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 32, 32, 16)   2320        activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 32, 32, 16)   64          conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 32, 32, 16)   0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 32, 32, 64)   1088        activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_112 (Add)                   (None, 32, 32, 64)   0           add_111[0][0]                    \n",
      "                                                                 conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 32, 32, 64)   256         add_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 32, 32, 64)   0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 16, 16, 64)   4160        activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 16, 16, 64)   256         conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 16, 16, 64)   0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 16, 16, 64)   36928       activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 16, 16, 64)   256         conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 16, 16, 64)   0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 16, 16, 128)  8320        add_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 16, 16, 128)  8320        activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_113 (Add)                   (None, 16, 16, 128)  0           conv2d_268[0][0]                 \n",
      "                                                                 conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 16, 16, 128)  512         add_113[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 16, 16, 128)  0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 16, 16, 64)   8256        activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 16, 16, 64)   256         conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 16, 16, 64)   0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 16, 16, 64)   36928       activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 16, 16, 64)   256         conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 16, 16, 64)   0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 16, 16, 128)  8320        activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_114 (Add)                   (None, 16, 16, 128)  0           add_113[0][0]                    \n",
      "                                                                 conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 16, 16, 128)  512         add_114[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 16, 16, 128)  0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 8, 8, 128)    16512       activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 8, 8, 128)    512         conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 8, 8, 128)    0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 8, 8, 128)    147584      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 8, 8, 128)    512         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 8, 8, 128)    0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 8, 8, 256)    33024       add_114[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 8, 8, 256)    33024       activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_115 (Add)                   (None, 8, 8, 256)    0           conv2d_275[0][0]                 \n",
      "                                                                 conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 8, 8, 256)    1024        add_115[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 8, 8, 256)    0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 8, 8, 128)    32896       activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 8, 8, 128)    512         conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 8, 8, 128)    0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 8, 8, 128)    147584      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 8, 8, 128)    512         conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 8, 8, 128)    0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 8, 8, 256)    33024       activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_116 (Add)                   (None, 8, 8, 256)    0           add_115[0][0]                    \n",
      "                                                                 conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 8, 8, 256)    1024        add_116[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 8, 8, 256)    0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 1, 1, 256)    0           activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 256)          0           average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 10)           2570        flatten_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 573,738\n",
      "Trainable params: 570,282\n",
      "Non-trainable params: 3,456\n",
      "__________________________________________________________________________________________________\n",
      "ResNet20v2\n",
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 1/10\n",
      "468/469 [============================>.] - ETA: 2s - loss: 1.2854 - acc: 0.6135Epoch 00001: val_acc improved from -inf to 0.54200, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v2_model.001.h5\n",
      "469/469 [==============================] - 1404s 3s/step - loss: 1.2845 - acc: 0.6138 - val_loss: 1.3634 - val_acc: 0.5420\n",
      "Learning rate:  0.001\n",
      "Epoch 2/10\n",
      "468/469 [============================>.] - ETA: 2s - loss: 0.7275 - acc: 0.7908Epoch 00002: val_acc did not improve\n",
      "469/469 [==============================] - 1389s 3s/step - loss: 0.7273 - acc: 0.7909 - val_loss: 2.5890 - val_acc: 0.3647\n",
      "Learning rate:  0.001\n",
      "Epoch 3/10\n",
      "468/469 [============================>.] - ETA: 2s - loss: 0.6283 - acc: 0.8250Epoch 00003: val_acc improved from 0.54200 to 0.70760, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v2_model.003.h5\n",
      "469/469 [==============================] - 1387s 3s/step - loss: 0.6280 - acc: 0.8251 - val_loss: 0.9200 - val_acc: 0.7076\n",
      "Learning rate:  0.001\n",
      "Epoch 4/10\n",
      "468/469 [============================>.] - ETA: 2s - loss: 0.5722 - acc: 0.8407Epoch 00004: val_acc improved from 0.70760 to 0.78430, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v2_model.004.h5\n",
      "469/469 [==============================] - 1388s 3s/step - loss: 0.5721 - acc: 0.8406 - val_loss: 0.7518 - val_acc: 0.7843\n",
      "Learning rate:  0.001\n",
      "Epoch 5/10\n",
      "468/469 [============================>.] - ETA: 2s - loss: 0.5379 - acc: 0.8505Epoch 00005: val_acc did not improve\n",
      "469/469 [==============================] - 1389s 3s/step - loss: 0.5379 - acc: 0.8505 - val_loss: 0.8311 - val_acc: 0.7237\n",
      "Learning rate:  0.001\n",
      "Epoch 6/10\n",
      "468/469 [============================>.] - ETA: 2s - loss: 0.5104 - acc: 0.8592Epoch 00006: val_acc improved from 0.78430 to 0.84720, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v2_model.006.h5\n",
      "469/469 [==============================] - 1389s 3s/step - loss: 0.5104 - acc: 0.8592 - val_loss: 0.5439 - val_acc: 0.8472\n",
      "Learning rate:  0.001\n",
      "Epoch 7/10\n",
      "468/469 [============================>.] - ETA: 2s - loss: 0.4916 - acc: 0.8651Epoch 00007: val_acc did not improve\n",
      "469/469 [==============================] - 1389s 3s/step - loss: 0.4917 - acc: 0.8651 - val_loss: 0.6776 - val_acc: 0.7946\n",
      "Learning rate:  0.001\n",
      "Epoch 8/10\n",
      "468/469 [============================>.] - ETA: 2s - loss: 0.4738 - acc: 0.8700Epoch 00008: val_acc did not improve\n",
      "469/469 [==============================] - 1389s 3s/step - loss: 0.4737 - acc: 0.8699 - val_loss: 0.6272 - val_acc: 0.8177\n",
      "Learning rate:  0.001\n",
      "Epoch 9/10\n",
      "468/469 [============================>.] - ETA: 2s - loss: 0.4580 - acc: 0.8746Epoch 00009: val_acc did not improve\n",
      "469/469 [==============================] - 1395s 3s/step - loss: 0.4580 - acc: 0.8747 - val_loss: 0.5458 - val_acc: 0.8389\n",
      "Learning rate:  0.001\n",
      "Epoch 10/10\n",
      "468/469 [============================>.] - ETA: 2s - loss: 0.4443 - acc: 0.8793Epoch 00010: val_acc did not improve\n",
      "469/469 [==============================] - 1391s 3s/step - loss: 0.4443 - acc: 0.8793 - val_loss: 0.5538 - val_acc: 0.8425\n",
      "10000/10000 [==============================] - 88s 9ms/step\n",
      "Test loss: 0.553788468837738\n",
      "Test accuracy: 0.8425\n"
     ]
    }
   ],
   "source": [
    "#resnet https://github.com/keras-team/keras/blob/master/examples/cifar10_resnet.py\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
    "epochs = 10\n",
    "data_augmentation = True\n",
    "num_classes = 10\n",
    "\n",
    "# Subtracting pixel mean improves accuracy\n",
    "subtract_pixel_mean = True\n",
    "\n",
    "# Model parameter\n",
    "# ----------------------------------------------------------------------------\n",
    "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
    "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
    "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
    "# ----------------------------------------------------------------------------\n",
    "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
    "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
    "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
    "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
    "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
    "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
    "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
    "# ---------------------------------------------------------------------------\n",
    "n = 2\n",
    "\n",
    "# Model version\n",
    "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
    "version = 2\n",
    "\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "# Load the CIFAR10 data.\n",
    "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Input image dimensions.\n",
    "input_shape = (28,28,1)#x_train2.shape[1:]\n",
    "\n",
    "# Normalize data.\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "#if subtract_pixel_mean:\n",
    "#    x_train_mean = np.mean(x_train, axis=0)\n",
    "#    x_train -= x_train_mean\n",
    "#    x_test -= x_train_mean\n",
    "\n",
    "print('x_train2 shape:', x_train2.shape)\n",
    "print(x_train2.shape[0], 'train samples')\n",
    "print(x_test2.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train2.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "def resnet_first_block(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            activation-bn-conv (False)\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    x = ZeroPadding2D(padding=(2, 2), data_format=None)(inputs)\n",
    "    \n",
    "    y = Conv2D(num_filters,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=strides,\n",
    "               padding='same',\n",
    "               kernel_initializer='he_normal',\n",
    "               kernel_regularizer=l2(1e-4))(x)\n",
    "    \n",
    "    return y\n",
    "\n",
    "def resnet_block(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            activation-bn-conv (False)\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = Conv2D(num_filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=strides,\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal',\n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation:\n",
    "            x = Activation(activation)(x)\n",
    "        return x\n",
    "    if batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = Activation('relu')(x)\n",
    "    x = Conv2D(num_filters,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=strides,\n",
    "               padding='same',\n",
    "               kernel_initializer='he_normal',\n",
    "               kernel_regularizer=l2(1e-4))(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    The number of filters doubles when the feature maps size\n",
    "    is halved.\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    inputs = Input(shape=input_shape)\n",
    "    num_filters = 16\n",
    "    num_sub_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    x = resnet_first_block(inputs=inputs)\n",
    "    # Instantiate convolutional base (stack of blocks).\n",
    "    for i in range(3):\n",
    "        for j in range(num_sub_blocks):\n",
    "            strides = 1\n",
    "            is_first_layer_but_not_first_block = j == 0 and i > 0\n",
    "            if is_first_layer_but_not_first_block:\n",
    "                strides = 2\n",
    "            y = resnet_block(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_block(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if is_first_layer_but_not_first_block:\n",
    "                x = resnet_block(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters = 2 * num_filters\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    Features maps sizes: 16(input), 64(1st sub_block), 128(2nd), 256(3rd)\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    inputs = Input(shape=input_shape)\n",
    "    num_filters_in = 16\n",
    "    num_filters_out = 64\n",
    "    filter_multiplier = 4\n",
    "    num_sub_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_first_block(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate convolutional base (stack of blocks).\n",
    "    activation = None\n",
    "    batch_normalization = False\n",
    "    for i in range(3):\n",
    "        if i > 0:\n",
    "            filter_multiplier = 2\n",
    "        num_filters_out = num_filters_in * filter_multiplier\n",
    "\n",
    "        for j in range(num_sub_blocks):\n",
    "            strides = 1\n",
    "            is_first_layer_but_not_first_block = j == 0 and i > 0\n",
    "            if is_first_layer_but_not_first_block:\n",
    "                strides = 2\n",
    "            y = resnet_block(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            y = resnet_block(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_block(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if j == 0:\n",
    "                x = resnet_block(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "if version == 2:\n",
    "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "else:\n",
    "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(model_type)\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "# Prepare model model saving directory.\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train2, y_train2,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test2, y_test2),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train2)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train2, y_train2, batch_size=128),\n",
    "                        validation_data=(x_test2, y_test2),\n",
    "                        epochs=10, verbose=1, workers=-1,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test2, y_test2, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "model.save(\"resnet20v2_fashionmnist_10epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (3, 3), activation=\"relu\", strides=(2, 2), padding=\"valid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  \"\"\"\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "  if sys.path[0] == '':\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "  del sys.path[0]\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\legacy\\layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:42: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:43: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:45: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:49: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:51: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:56: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:57: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:58: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:59: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:66: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:67: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:68: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:69: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:74: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), padding=\"valid\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:77: UserWarning: Update your `AveragePooling2D` call to the Keras 2 API: `AveragePooling2D((13, 13), strides=(1, 1), padding=\"same\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:83: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 13, 13, 96)   960         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 6, 6, 96)     0           conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 6, 6, 16)     1552        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 6, 6, 64)     1088        conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 6, 6, 64)     9280        conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_1 (Merge)                 (None, 12, 6, 64)    0           conv2d_281[0][0]                 \n",
      "                                                                 conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 12, 6, 64)    0           merge_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 12, 6, 16)    1040        activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 12, 6, 64)    1088        conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 12, 6, 64)    9280        conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_2 (Merge)                 (None, 24, 6, 64)    0           conv2d_284[0][0]                 \n",
      "                                                                 conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 24, 6, 64)    0           merge_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 24, 6, 32)    2080        activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 24, 6, 128)   4224        conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 24, 6, 128)   36992       conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_3 (Merge)                 (None, 48, 6, 128)   0           conv2d_287[0][0]                 \n",
      "                                                                 conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 48, 6, 128)   0           merge_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 24, 3, 128)   0           activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 24, 3, 32)    4128        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 24, 3, 128)   4224        conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 24, 3, 128)   36992       conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_4 (Merge)                 (None, 48, 3, 128)   0           conv2d_290[0][0]                 \n",
      "                                                                 conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 48, 3, 128)   0           merge_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 48, 3, 48)    6192        activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 48, 3, 192)   9408        conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 48, 3, 192)   83136       conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_5 (Merge)                 (None, 96, 3, 192)   0           conv2d_293[0][0]                 \n",
      "                                                                 conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 96, 3, 192)   0           merge_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 96, 3, 48)    9264        activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 96, 3, 192)   9408        conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 96, 3, 192)   83136       conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_6 (Merge)                 (None, 192, 3, 192)  0           conv2d_296[0][0]                 \n",
      "                                                                 conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 192, 3, 192)  0           merge_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 192, 3, 64)   12352       activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 192, 3, 256)  16640       conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 192, 3, 256)  147712      conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_7 (Merge)                 (None, 384, 3, 256)  0           conv2d_299[0][0]                 \n",
      "                                                                 conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 384, 3, 256)  0           merge_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 192, 1, 256)  0           activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 192, 1, 64)   16448       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 192, 1, 256)  16640       conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 192, 1, 256)  147712      conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_8 (Merge)                 (None, 384, 1, 256)  0           conv2d_302[0][0]                 \n",
      "                                                                 conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 384, 1, 256)  0           merge_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 384, 1, 256)  0           activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 384, 1, 10)   2570        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 384, 1, 10)   0           conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 3840)         0           average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 10)           38410       flatten_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 711,956\n",
      "Trainable params: 711,956\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 1412s 24ms/step - loss: 1.0159 - acc: 0.6209 - val_loss: 0.6674 - val_acc: 0.7605\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1394s 23ms/step - loss: 0.5400 - acc: 0.7963 - val_loss: 0.5087 - val_acc: 0.8003\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1391s 23ms/step - loss: 0.4419 - acc: 0.8393 - val_loss: 0.4734 - val_acc: 0.8268\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1388s 23ms/step - loss: 0.3894 - acc: 0.8585 - val_loss: 0.4177 - val_acc: 0.8530\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1391s 23ms/step - loss: 0.3589 - acc: 0.8695 - val_loss: 0.3827 - val_acc: 0.8590\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1389s 23ms/step - loss: 0.3351 - acc: 0.8771 - val_loss: 0.3732 - val_acc: 0.8616\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1388s 23ms/step - loss: 0.3151 - acc: 0.8837 - val_loss: 0.3722 - val_acc: 0.8697\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1385s 23ms/step - loss: 0.2994 - acc: 0.8900 - val_loss: 0.3323 - val_acc: 0.8823\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1385s 23ms/step - loss: 0.2854 - acc: 0.8944 - val_loss: 0.3246 - val_acc: 0.8819\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1384s 23ms/step - loss: 0.2720 - acc: 0.9001 - val_loss: 0.3323 - val_acc: 0.8813\n",
      "10000/10000 [==============================] - 72s 7ms/step\n",
      "Test score: 0.3322905200958252\n",
      "Test accuracy: 0.8813\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, merge\n",
    "input_layer = Input(shape=(28, 28,1), name=\"input\")\n",
    "\n",
    "#conv 1\n",
    "conv1 = Convolution2D(96, 3, 3, activation='relu', init='glorot_uniform',subsample=(2,2),border_mode='valid')(input_layer)\n",
    "\n",
    "#maxpool 1\n",
    "maxpool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "\n",
    "#fire 1\n",
    "fire2_squeeze = Convolution2D(16, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(maxpool1)\n",
    "fire2_expand1 = Convolution2D(64, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire2_squeeze)\n",
    "fire2_expand2 = Convolution2D(64, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire2_squeeze)\n",
    "merge1 = merge(inputs=[fire2_expand1, fire2_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire2 = Activation(\"linear\")(merge1)\n",
    "\n",
    "#fire 2\n",
    "fire3_squeeze = Convolution2D(16, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire2)\n",
    "fire3_expand1 = Convolution2D(64, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire3_squeeze)\n",
    "fire3_expand2 = Convolution2D(64, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire3_squeeze)\n",
    "merge2 = merge(inputs=[fire3_expand1, fire3_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire3 = Activation(\"linear\")(merge2)\n",
    "\n",
    "#fire 3\n",
    "fire4_squeeze = Convolution2D(32, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire3)\n",
    "fire4_expand1 = Convolution2D(128, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire4_squeeze)\n",
    "fire4_expand2 = Convolution2D(128, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire4_squeeze)\n",
    "merge3 = merge(inputs=[fire4_expand1, fire4_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire4 = Activation(\"linear\")(merge3)\n",
    "\n",
    "#maxpool 4\n",
    "maxpool4 = MaxPooling2D((2,2))(fire4)\n",
    "\n",
    "#fire 5\n",
    "fire5_squeeze = Convolution2D(32, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(maxpool4)\n",
    "fire5_expand1 = Convolution2D(128, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire5_squeeze)\n",
    "fire5_expand2 = Convolution2D(128, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire5_squeeze)\n",
    "merge5 = merge(inputs=[fire5_expand1, fire5_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire5 = Activation(\"linear\")(merge5)\n",
    "\n",
    "#fire 6\n",
    "fire6_squeeze = Convolution2D(48, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire5)\n",
    "fire6_expand1 = Convolution2D(192, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire6_squeeze)\n",
    "fire6_expand2 = Convolution2D(192, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire6_squeeze)\n",
    "merge6 = merge(inputs=[fire6_expand1, fire6_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire6 = Activation(\"linear\")(merge6)\n",
    "\n",
    "#fire 7\n",
    "fire7_squeeze = Convolution2D(48, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire6)\n",
    "fire7_expand1 = Convolution2D(192, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire7_squeeze)\n",
    "fire7_expand2 = Convolution2D(192, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire7_squeeze)\n",
    "merge7 = merge(inputs=[fire7_expand1, fire7_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire7 =Activation(\"linear\")(merge7)\n",
    "\n",
    "#fire 8\n",
    "fire8_squeeze = Convolution2D(64, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire7)\n",
    "fire8_expand1 = Convolution2D(256, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire8_squeeze)\n",
    "fire8_expand2 = Convolution2D(256, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire8_squeeze)\n",
    "merge8 = merge(inputs=[fire8_expand1, fire8_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire8 = Activation(\"linear\")(merge8)\n",
    "\n",
    "#maxpool 8\n",
    "maxpool8 = MaxPooling2D((2,2))(fire8)\n",
    "\n",
    "#fire 9\n",
    "fire9_squeeze = Convolution2D(64, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(maxpool8)\n",
    "fire9_expand1 = Convolution2D(256, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire9_squeeze)\n",
    "fire9_expand2 = Convolution2D(256, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire9_squeeze)\n",
    "merge8 = merge(inputs=[fire9_expand1, fire9_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire9 = Activation(\"linear\")(merge8)\n",
    "fire9_dropout = Dropout(0.5)(fire9)\n",
    "\n",
    "#conv 10\n",
    "conv10 = Convolution2D(10, 1, 1, init='glorot_uniform',border_mode='valid')(fire9_dropout)\n",
    "\n",
    "#avgpool 1\n",
    "avgpool10 = AveragePooling2D((13,13), strides=(1,1), border_mode='same')(conv10)\n",
    "\n",
    "flatten = Flatten()(avgpool10)\n",
    "\n",
    "softmax = Dense(10, activation=\"softmax\")(flatten)\n",
    "\n",
    "model = Model(input=input_layer, output=softmax)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adadelta', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train2, y_train2, batch_size=128, epochs=10, validation_data=(x_test2, y_test2))\n",
    " \n",
    "score = model.evaluate(x_test2, y_test2, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    " \n",
    "model.save(\"squeezenet_fashionmnist_10epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
