{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST\n",
    "\n",
    "#import autosklearn.classification\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from keras.datasets import mnist\n",
    "from keras.datasets import cifar10\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import openml as oml\n",
    "from keras.models import load_model\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "import openml as oml\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "oml.config.apikey = 'b15b073c6fea6dc55b08f051f5e1abf9'\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16.0, 4.0) # Set default figure size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n",
      "y_train shape: (60000,)\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "y_train shape: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    " \n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    " \n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,505,034\n",
      "Trainable params: 1,505,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 727s 12ms/step - loss: 1.2878 - acc: 0.8204 - val_loss: 0.0622 - val_acc: 0.9780\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 690s 11ms/step - loss: 0.1328 - acc: 0.9593 - val_loss: 0.0445 - val_acc: 0.9838\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 514s 9ms/step - loss: 0.0953 - acc: 0.9715 - val_loss: 0.0288 - val_acc: 0.9904\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 435s 7ms/step - loss: 0.0720 - acc: 0.9772 - val_loss: 0.0238 - val_acc: 0.9919\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 436s 7ms/step - loss: 0.0606 - acc: 0.9813 - val_loss: 0.0224 - val_acc: 0.9920\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 435s 7ms/step - loss: 0.0534 - acc: 0.9832 - val_loss: 0.0234 - val_acc: 0.9916\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 435s 7ms/step - loss: 0.0490 - acc: 0.9855 - val_loss: 0.0176 - val_acc: 0.9943\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 440s 7ms/step - loss: 0.0421 - acc: 0.9873 - val_loss: 0.0201 - val_acc: 0.9932\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 437s 7ms/step - loss: 0.0414 - acc: 0.9871 - val_loss: 0.0156 - val_acc: 0.9947\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 437s 7ms/step - loss: 0.0371 - acc: 0.9885 - val_loss: 0.0149 - val_acc: 0.9946\n",
      "10000/10000 [==============================] - 25s 2ms/step\n",
      "Test score: 0.014886428708791572\n",
      "Test accuracy: 0.9946\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#vgg-like\n",
    "\n",
    "model3=Sequential()\n",
    "model3.add(Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", \n",
    "          input_shape=x_train.shape[1:], activation='relu'))\n",
    "model3.add(Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation='relu'))\n",
    "model3.add(Conv2D(filters=256, kernel_size=(3, 3), padding=\"valid\", activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(256))\n",
    "model3.add(LeakyReLU())\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(256))\n",
    "model3.add(LeakyReLU())\n",
    "#model2.add(Dropout(0.5))\n",
    "model3.add(Dense(10, activation='softmax'))\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "model3.summary()\n",
    "\n",
    "model3.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))\n",
    " \n",
    "score = model3.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    " \n",
    "model3.save(\"vgglike_mnist_10epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AlexNet(weights_path=None, heatmap=False):\n",
    "    if heatmap:\n",
    "        inputs = Input(shape=(3,None,None))\n",
    "    else:\n",
    "        inputs = Input(shape=(3,227,227))\n",
    "\n",
    "    conv_1 = Convolution2D(96, 11, 11,subsample=(4,4),activation='relu',\n",
    "                           name='conv_1')(inputs)\n",
    "\n",
    "    conv_2 = MaxPooling2D((3, 3), strides=(2,2))(conv_1)\n",
    "    conv_2 = crosschannelnormalization(name=\"convpool_1\")(conv_2)\n",
    "    conv_2 = ZeroPadding2D((2,2))(conv_2)\n",
    "    conv_2 = merge([\n",
    "        Convolution2D(128,5,5,activation=\"relu\",name='conv_2_'+str(i+1))(\n",
    "            splittensor(ratio_split=2,id_split=i)(conv_2)\n",
    "        ) for i in range(2)], mode='concat',concat_axis=1,name=\"conv_2\")\n",
    "\n",
    "    conv_3 = MaxPooling2D((3, 3), strides=(2, 2))(conv_2)\n",
    "    conv_3 = crosschannelnormalization()(conv_3)\n",
    "    conv_3 = ZeroPadding2D((1,1))(conv_3)\n",
    "    conv_3 = Convolution2D(384,3,3,activation='relu',name='conv_3')(conv_3)\n",
    "\n",
    "    conv_4 = ZeroPadding2D((1,1))(conv_3)\n",
    "    conv_4 = merge([\n",
    "        Convolution2D(192,3,3,activation=\"relu\",name='conv_4_'+str(i+1))(\n",
    "            splittensor(ratio_split=2,id_split=i)(conv_4)\n",
    "        ) for i in range(2)], mode='concat',concat_axis=1,name=\"conv_4\")\n",
    "\n",
    "    conv_5 = ZeroPadding2D((1,1))(conv_4)\n",
    "    conv_5 = merge([\n",
    "        Convolution2D(128,3,3,activation=\"relu\",name='conv_5_'+str(i+1))(\n",
    "            splittensor(ratio_split=2,id_split=i)(conv_5)\n",
    "        ) for i in range(2)], mode='concat',concat_axis=1,name=\"conv_5\")\n",
    "\n",
    "    dense_1 = MaxPooling2D((3, 3), strides=(2,2),name=\"convpool_5\")(conv_5)\n",
    "\n",
    "    if heatmap:\n",
    "        dense_1 = Convolution2D(4096,6,6,activation=\"relu\",name=\"dense_1\")(dense_1)\n",
    "        dense_2 = Convolution2D(4096,1,1,activation=\"relu\",name=\"dense_2\")(dense_1)\n",
    "        dense_3 = Convolution2D(1000, 1,1,name=\"dense_3\")(dense_2)\n",
    "        prediction = Softmax4D(axis=1,name=\"softmax\")(dense_3)\n",
    "    else:\n",
    "        dense_1 = Flatten(name=\"flatten\")(dense_1)\n",
    "        dense_1 = Dense(4096, activation='relu',name='dense_1')(dense_1)\n",
    "        dense_2 = Dropout(0.5)(dense_1)\n",
    "        dense_2 = Dense(4096, activation='relu',name='dense_2')(dense_2)\n",
    "        dense_3 = Dropout(0.5)(dense_2)\n",
    "        dense_3 = Dense(1000,name='dense_3')(dense_3)\n",
    "        prediction = Activation(\"softmax\",name=\"softmax\")(dense_3)\n",
    "\n",
    "\n",
    "    model = Model(input=inputs, output=prediction)\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Can't open attribute (can't locate attribute: 'layer_names')\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-215e6bdef9ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m# Test pretrained model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVGG_16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'vgg16_weights.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[0msgd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-215e6bdef9ca>\u001b[0m in \u001b[0;36mVGG_16\u001b[1;34m(weights_path)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mweights_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name)\u001b[0m\n\u001b[0;32m    731\u001b[0m             \u001b[0mtopology\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 733\u001b[1;33m             \u001b[0mtopology\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    734\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'close'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m   3102\u001b[0m             \u001b[0mfiltered_layers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3104\u001b[1;33m     \u001b[0mlayer_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'layer_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3105\u001b[0m     \u001b[0mfiltered_layer_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3106\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayer_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\_hl\\attrs.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \"\"\" Read the value of an attribute.\n\u001b[0;32m     59\u001b[0m         \"\"\"\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0mattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_empty_dataspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5a.pyx\u001b[0m in \u001b[0;36mh5py.h5a.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Can't open attribute (can't locate attribute: 'layer_names')\""
     ]
    }
   ],
   "source": [
    "def VGG_16(weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(128,128,1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(128, (3, 3),activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Test pretrained model\n",
    "model = VGG_16('vgg16_weights.h5')\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "#out = model.predict(im)\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "#print np.argmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_obtain_input_shape() got an unexpected keyword argument 'include_top'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-023843efa06c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimagenet_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'imagenet'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\autonet\\vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[0;32m    100\u001b[0m                                       \u001b[0mmin_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                                       \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m                                       include_top=include_top)\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: _obtain_input_shape() got an unexpected keyword argument 'include_top'"
     ]
    }
   ],
   "source": [
    "from vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from imagenet_utils import preprocess_input\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "\n",
    "\n",
    "#features = model.predict(x)\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "#print np.argmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (60000, 10)\n",
      "Learning rate:  0.001\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_31 (ZeroPadding2 (None, 32, 32, 1)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 16)   160         zero_padding2d_31[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 16)   2320        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 16)   0           conv2d_31[0][0]                  \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 16)   0           activation_2[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 16)   0           activation_4[0][0]               \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 16)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 32)   4640        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 32)   128         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 32)   9248        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 32)   544         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 32)   0           conv2d_40[0][0]                  \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 32)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 32)   9248        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 32)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 32)   0           activation_8[0][0]               \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 32)   0           activation_10[0][0]              \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 32)   0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 64)     18496       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 64)     256         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 64)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 8, 8, 64)     36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 8, 8, 64)     2112        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 64)     0           conv2d_47[0][0]                  \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 8, 8, 64)     36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 64)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 64)     0           activation_14[0][0]              \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 8, 8, 64)     36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 64)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 64)     0           activation_16[0][0]              \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 64)     0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 64)     0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 64)           0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           650         flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 274,090\n",
      "Trainable params: 272,746\n",
      "Non-trainable params: 1,344\n",
      "__________________________________________________________________________________________________\n",
      "ResNet20v1\n",
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 1/10\n",
      "468/469 [============================>.] - ETA: 1s - loss: 1.2339 - acc: 0.7197Epoch 00001: val_acc improved from -inf to 0.74680, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v1_model.001.h5\n",
      "469/469 [==============================] - 797s 2s/step - loss: 1.2324 - acc: 0.7199 - val_loss: 0.8880 - val_acc: 0.7468\n",
      "Learning rate:  0.001\n",
      "Epoch 2/10\n",
      "468/469 [============================>.] - ETA: 1s - loss: 0.3736 - acc: 0.9197Epoch 00002: val_acc improved from 0.74680 to 0.91790, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v1_model.002.h5\n",
      "469/469 [==============================] - 795s 2s/step - loss: 0.3732 - acc: 0.9198 - val_loss: 0.3858 - val_acc: 0.9179\n",
      "Learning rate:  0.001\n",
      "Epoch 3/10\n",
      "468/469 [============================>.] - ETA: 1s - loss: 0.2740 - acc: 0.9491Epoch 00003: val_acc improved from 0.91790 to 0.94260, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v1_model.003.h5\n",
      "469/469 [==============================] - 794s 2s/step - loss: 0.2740 - acc: 0.9491 - val_loss: 0.2784 - val_acc: 0.9426\n",
      "Learning rate:  0.001\n",
      "Epoch 4/10\n",
      "468/469 [============================>.] - ETA: 1s - loss: 0.2292 - acc: 0.9603Epoch 00004: val_acc improved from 0.94260 to 0.95280, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v1_model.004.h5\n",
      "469/469 [==============================] - 794s 2s/step - loss: 0.2292 - acc: 0.9603 - val_loss: 0.2487 - val_acc: 0.9528\n",
      "Learning rate:  0.001\n",
      "Epoch 5/10\n",
      "468/469 [============================>.] - ETA: 1s - loss: 0.1986 - acc: 0.9667Epoch 00005: val_acc did not improve\n",
      "469/469 [==============================] - 794s 2s/step - loss: 0.1985 - acc: 0.9667 - val_loss: 0.3286 - val_acc: 0.9228\n",
      "Learning rate:  0.001\n",
      "Epoch 6/10\n",
      "468/469 [============================>.] - ETA: 1s - loss: 0.1778 - acc: 0.9717Epoch 00006: val_acc did not improve\n",
      "469/469 [==============================] - 794s 2s/step - loss: 0.1778 - acc: 0.9716 - val_loss: 0.2946 - val_acc: 0.9281\n",
      "Learning rate:  0.001\n",
      "Epoch 7/10\n",
      "468/469 [============================>.] - ETA: 1s - loss: 0.1607 - acc: 0.9743Epoch 00007: val_acc did not improve\n",
      "469/469 [==============================] - 793s 2s/step - loss: 0.1606 - acc: 0.9744 - val_loss: 0.2483 - val_acc: 0.9496\n",
      "Learning rate:  0.001\n",
      "Epoch 8/10\n",
      "468/469 [============================>.] - ETA: 1s - loss: 0.1493 - acc: 0.9761Epoch 00008: val_acc improved from 0.95280 to 0.97180, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v1_model.008.h5\n",
      "469/469 [==============================] - 795s 2s/step - loss: 0.1492 - acc: 0.9761 - val_loss: 0.1672 - val_acc: 0.9718\n",
      "Learning rate:  0.001\n",
      "Epoch 9/10\n",
      "468/469 [============================>.] - ETA: 1s - loss: 0.1408 - acc: 0.9780Epoch 00009: val_acc did not improve\n",
      "469/469 [==============================] - 793s 2s/step - loss: 0.1408 - acc: 0.9780 - val_loss: 0.3673 - val_acc: 0.9015\n",
      "Learning rate:  0.001\n",
      "Epoch 10/10\n",
      "468/469 [============================>.] - ETA: 1s - loss: 0.1338 - acc: 0.9788Epoch 00010: val_acc did not improve\n",
      "469/469 [==============================] - 794s 2s/step - loss: 0.1338 - acc: 0.9788 - val_loss: 0.2923 - val_acc: 0.9246\n",
      "10000/10000 [==============================] - 49s 5ms/step\n",
      "Test loss: 0.2923151980638504\n",
      "Test accuracy: 0.9246\n"
     ]
    }
   ],
   "source": [
    "#resnet https://github.com/keras-team/keras/blob/master/examples/cifar10_resnet.py\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
    "epochs = 10\n",
    "data_augmentation = True\n",
    "num_classes = 10\n",
    "\n",
    "# Subtracting pixel mean improves accuracy\n",
    "subtract_pixel_mean = True\n",
    "\n",
    "# Model parameter\n",
    "# ----------------------------------------------------------------------------\n",
    "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
    "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
    "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
    "# ----------------------------------------------------------------------------\n",
    "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
    "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
    "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
    "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
    "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
    "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
    "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
    "# ---------------------------------------------------------------------------\n",
    "n = 3\n",
    "\n",
    "# Model version\n",
    "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
    "version = 1\n",
    "\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "# Load the CIFAR10 data.\n",
    "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Input image dimensions.\n",
    "input_shape = (28,28,1)#x_train.shape[1:]\n",
    "\n",
    "# Normalize data.\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "#if subtract_pixel_mean:\n",
    "#    x_train_mean = np.mean(x_train, axis=0)\n",
    "#    x_train -= x_train_mean\n",
    "#    x_test -= x_train_mean\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "def resnet_first_block(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            activation-bn-conv (False)\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    x = ZeroPadding2D(padding=(2, 2), data_format=None)(inputs)\n",
    "    \n",
    "    y = Conv2D(num_filters,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=strides,\n",
    "               padding='same',\n",
    "               kernel_initializer='he_normal',\n",
    "               kernel_regularizer=l2(1e-4))(x)\n",
    "    \n",
    "    return y\n",
    "\n",
    "def resnet_block(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            activation-bn-conv (False)\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = Conv2D(num_filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=strides,\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal',\n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation:\n",
    "            x = Activation(activation)(x)\n",
    "        return x\n",
    "    if batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = Activation('relu')(x)\n",
    "    x = Conv2D(num_filters,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=strides,\n",
    "               padding='same',\n",
    "               kernel_initializer='he_normal',\n",
    "               kernel_regularizer=l2(1e-4))(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    The number of filters doubles when the feature maps size\n",
    "    is halved.\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    inputs = Input(shape=input_shape)\n",
    "    num_filters = 16\n",
    "    num_sub_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    x = resnet_first_block(inputs=inputs)\n",
    "    # Instantiate convolutional base (stack of blocks).\n",
    "    for i in range(3):\n",
    "        for j in range(num_sub_blocks):\n",
    "            strides = 1\n",
    "            is_first_layer_but_not_first_block = j == 0 and i > 0\n",
    "            if is_first_layer_but_not_first_block:\n",
    "                strides = 2\n",
    "            y = resnet_block(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_block(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if is_first_layer_but_not_first_block:\n",
    "                x = resnet_block(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters = 2 * num_filters\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    Features maps sizes: 16(input), 64(1st sub_block), 128(2nd), 256(3rd)\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    inputs = Input(shape=input_shape)\n",
    "    num_filters_in = 16\n",
    "    num_filters_out = 64\n",
    "    filter_multiplier = 4\n",
    "    num_sub_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_block(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate convolutional base (stack of blocks).\n",
    "    activation = None\n",
    "    batch_normalization = False\n",
    "    for i in range(3):\n",
    "        if i > 0:\n",
    "            filter_multiplier = 2\n",
    "        num_filters_out = num_filters_in * filter_multiplier\n",
    "\n",
    "        for j in range(num_sub_blocks):\n",
    "            strides = 1\n",
    "            is_first_layer_but_not_first_block = j == 0 and i > 0\n",
    "            if is_first_layer_but_not_first_block:\n",
    "                strides = 2\n",
    "            y = resnet_block(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            y = resnet_block(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_block(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if j == 0:\n",
    "                x = resnet_block(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "if version == 2:\n",
    "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "else:\n",
    "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(model_type)\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "# Prepare model model saving directory.\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=10, verbose=1, workers=-1,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "model.save(\"resnet20v1_mnist_10epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (60000, 10)\n",
      "Learning rate:  0.001\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_32 (ZeroPadding2 (None, 32, 32, 1)    0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 32, 32, 16)   160         zero_padding2d_32[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 32, 32, 16)   272         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 32, 32, 16)   64          conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 32, 32, 16)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 32, 32, 16)   2320        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 32, 32, 16)   64          conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 32, 32, 16)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 32, 32, 64)   1088        conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 32, 32, 64)   1088        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 32, 32, 64)   0           conv2d_78[0][0]                  \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 32, 32, 64)   256         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 32, 32, 64)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 32, 32, 16)   1040        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 32, 32, 16)   64          conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 32, 32, 16)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 32, 32, 16)   2320        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 32, 32, 16)   64          conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 32, 32, 16)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 32, 32, 64)   1088        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 32, 32, 64)   0           add_16[0][0]                     \n",
      "                                                                 conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 32, 32, 64)   256         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 32, 32, 64)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 16, 16, 64)   4160        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 64)   256         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 64)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 16, 16, 64)   36928       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 64)   256         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 64)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 16, 16, 128)  8320        add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 16, 16, 128)  8320        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 16, 16, 128)  0           conv2d_85[0][0]                  \n",
      "                                                                 conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 128)  512         add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 128)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 16, 16, 64)   8256        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 64)   256         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 64)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 16, 16, 64)   36928       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 64)   256         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 64)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 16, 16, 128)  8320        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 16, 16, 128)  0           add_18[0][0]                     \n",
      "                                                                 conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 128)  512         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 128)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 128)    16512       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 8, 8, 128)    512         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 8, 8, 128)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 128)    147584      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 128)    512         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 128)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 256)    33024       add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 256)    33024       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 8, 8, 256)    0           conv2d_92[0][0]                  \n",
      "                                                                 conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 256)    1024        add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 256)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 128)    32896       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 128)    512         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 128)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 128)    147584      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 128)    512         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 128)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 8, 8, 256)    33024       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 8, 8, 256)    0           add_20[0][0]                     \n",
      "                                                                 conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 256)    1024        add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 8, 256)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 1, 1, 256)    0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 256)          0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           2570        flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 573,738\n",
      "Trainable params: 570,282\n",
      "Non-trainable params: 3,456\n",
      "__________________________________________________________________________________________________\n",
      "ResNet20v2\n",
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 1/10\n",
      "468/469 [============================>.] - ETA: 4s - loss: 1.3102 - acc: 0.6238Epoch 00001: val_acc improved from -inf to 0.15900, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v2_model.001.h5\n",
      "469/469 [==============================] - 2082s 4s/step - loss: 1.3087 - acc: 0.6244 - val_loss: 3.1491 - val_acc: 0.1590\n",
      "Learning rate:  0.001\n",
      "Epoch 2/10\n",
      "468/469 [============================>.] - ETA: 4s - loss: 0.3895 - acc: 0.9366Epoch 00002: val_acc improved from 0.15900 to 0.89580, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v2_model.002.h5\n",
      "469/469 [==============================] - 2192s 5s/step - loss: 0.3894 - acc: 0.9367 - val_loss: 0.4897 - val_acc: 0.8958\n",
      "Learning rate:  0.001\n",
      "Epoch 3/10\n",
      "468/469 [============================>.] - ETA: 2s - loss: 0.2860 - acc: 0.9567Epoch 00003: val_acc did not improve\n",
      "469/469 [==============================] - 1435s 3s/step - loss: 0.2861 - acc: 0.9566 - val_loss: 0.8452 - val_acc: 0.7646\n",
      "Learning rate:  0.001\n",
      "Epoch 4/10\n",
      "468/469 [============================>.] - ETA: 2s - loss: 0.2461 - acc: 0.9656Epoch 00004: val_acc improved from 0.89580 to 0.92910, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v2_model.004.h5\n",
      "469/469 [==============================] - 1390s 3s/step - loss: 0.2460 - acc: 0.9656 - val_loss: 0.3502 - val_acc: 0.9291\n",
      "Learning rate:  0.001\n",
      "Epoch 5/10\n",
      "468/469 [============================>.] - ETA: 2s - loss: 0.2243 - acc: 0.9684Epoch 00005: val_acc did not improve\n",
      "469/469 [==============================] - 1389s 3s/step - loss: 0.2243 - acc: 0.9684 - val_loss: 0.3406 - val_acc: 0.9281\n",
      "Learning rate:  0.001\n",
      "Epoch 6/10\n",
      "468/469 [============================>.] - ETA: 2s - loss: 0.2105 - acc: 0.9701Epoch 00006: val_acc improved from 0.92910 to 0.95290, saving model to C:\\Users\\illia\\autonet\\saved_models\\cifar10_ResNet20v2_model.006.h5\n",
      "469/469 [==============================] - 1387s 3s/step - loss: 0.2104 - acc: 0.9701 - val_loss: 0.2606 - val_acc: 0.9529\n",
      "Learning rate:  0.001\n",
      "Epoch 7/10\n",
      "468/469 [============================>.] - ETA: 2s - loss: 0.1967 - acc: 0.9728Epoch 00007: val_acc did not improve\n",
      "469/469 [==============================] - 1383s 3s/step - loss: 0.1965 - acc: 0.9728 - val_loss: 0.3554 - val_acc: 0.9142\n",
      "Learning rate:  0.001\n",
      "Epoch 8/10\n",
      "468/469 [============================>.] - ETA: 2s - loss: 0.1881 - acc: 0.9731Epoch 00008: val_acc did not improve\n",
      "469/469 [==============================] - 1387s 3s/step - loss: 0.1883 - acc: 0.9731 - val_loss: 0.2838 - val_acc: 0.9373\n",
      "Learning rate:  0.001\n",
      "Epoch 9/10\n",
      "468/469 [============================>.] - ETA: 2s - loss: 0.1763 - acc: 0.9758Epoch 00009: val_acc did not improve\n",
      "469/469 [==============================] - 1384s 3s/step - loss: 0.1763 - acc: 0.9757 - val_loss: 0.3000 - val_acc: 0.9351\n",
      "Learning rate:  0.001\n",
      "Epoch 10/10\n",
      "468/469 [============================>.] - ETA: 2s - loss: 0.1722 - acc: 0.9755Epoch 00010: val_acc did not improve\n",
      "469/469 [==============================] - 1390s 3s/step - loss: 0.1721 - acc: 0.9755 - val_loss: 0.3611 - val_acc: 0.9222\n",
      "10000/10000 [==============================] - 88s 9ms/step\n",
      "Test loss: 0.36106399574279785\n",
      "Test accuracy: 0.9222\n"
     ]
    }
   ],
   "source": [
    "#resnet https://github.com/keras-team/keras/blob/master/examples/cifar10_resnet.py\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
    "epochs = 10\n",
    "data_augmentation = True\n",
    "num_classes = 10\n",
    "\n",
    "# Subtracting pixel mean improves accuracy\n",
    "subtract_pixel_mean = True\n",
    "\n",
    "# Model parameter\n",
    "# ----------------------------------------------------------------------------\n",
    "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
    "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
    "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
    "# ----------------------------------------------------------------------------\n",
    "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
    "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
    "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
    "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
    "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
    "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
    "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
    "# ---------------------------------------------------------------------------\n",
    "n = 2\n",
    "\n",
    "# Model version\n",
    "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
    "version = 2\n",
    "\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "# Load the CIFAR10 data.\n",
    "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Input image dimensions.\n",
    "input_shape = (28,28,1)#x_train.shape[1:]\n",
    "\n",
    "# Normalize data.\n",
    "#x_train = x_train.astype('float32') / 255\n",
    "#x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "#if subtract_pixel_mean:\n",
    "#    x_train_mean = np.mean(x_train, axis=0)\n",
    "#    x_train -= x_train_mean\n",
    "#    x_test -= x_train_mean\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "def resnet_first_block(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            activation-bn-conv (False)\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    x = ZeroPadding2D(padding=(2, 2), data_format=None)(inputs)\n",
    "    \n",
    "    y = Conv2D(num_filters,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=strides,\n",
    "               padding='same',\n",
    "               kernel_initializer='he_normal',\n",
    "               kernel_regularizer=l2(1e-4))(x)\n",
    "    \n",
    "    return y\n",
    "\n",
    "def resnet_block(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            activation-bn-conv (False)\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = Conv2D(num_filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=strides,\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal',\n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation:\n",
    "            x = Activation(activation)(x)\n",
    "        return x\n",
    "    if batch_normalization:\n",
    "        x = BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = Activation('relu')(x)\n",
    "    x = Conv2D(num_filters,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=strides,\n",
    "               padding='same',\n",
    "               kernel_initializer='he_normal',\n",
    "               kernel_regularizer=l2(1e-4))(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    The number of filters doubles when the feature maps size\n",
    "    is halved.\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    inputs = Input(shape=input_shape)\n",
    "    num_filters = 16\n",
    "    num_sub_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    x = resnet_first_block(inputs=inputs)\n",
    "    # Instantiate convolutional base (stack of blocks).\n",
    "    for i in range(3):\n",
    "        for j in range(num_sub_blocks):\n",
    "            strides = 1\n",
    "            is_first_layer_but_not_first_block = j == 0 and i > 0\n",
    "            if is_first_layer_but_not_first_block:\n",
    "                strides = 2\n",
    "            y = resnet_block(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_block(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if is_first_layer_but_not_first_block:\n",
    "                x = resnet_block(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters = 2 * num_filters\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    Features maps sizes: 16(input), 64(1st sub_block), 128(2nd), 256(3rd)\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    inputs = Input(shape=input_shape)\n",
    "    num_filters_in = 16\n",
    "    num_filters_out = 64\n",
    "    filter_multiplier = 4\n",
    "    num_sub_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_first_block(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate convolutional base (stack of blocks).\n",
    "    activation = None\n",
    "    batch_normalization = False\n",
    "    for i in range(3):\n",
    "        if i > 0:\n",
    "            filter_multiplier = 2\n",
    "        num_filters_out = num_filters_in * filter_multiplier\n",
    "\n",
    "        for j in range(num_sub_blocks):\n",
    "            strides = 1\n",
    "            is_first_layer_but_not_first_block = j == 0 and i > 0\n",
    "            if is_first_layer_but_not_first_block:\n",
    "                strides = 2\n",
    "            y = resnet_block(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            y = resnet_block(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_block(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if j == 0:\n",
    "                x = resnet_block(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "if version == 2:\n",
    "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "else:\n",
    "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(model_type)\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "# Prepare model model saving directory.\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=128),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=10, verbose=1, workers=-1,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "model.save(\"resnet20v2_mnist_10epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-68b2a0935974>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-24-68b2a0935974>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    input_shape = (:,28,28,1)\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import MaxPool2D\n",
    "from keras import optimizers\n",
    "input_shape = (28,28,1)\n",
    "img_input = Input(shape=input_shape)\n",
    "        # x = ZeroPadding2D((3, 3))(img_input)\n",
    "x = Conv2D(96, (7, 7), strides=(2, 2), name='conv1')(img_input)\n",
    "        # (55, 55, 96)\n",
    "x = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='pool1')(x)\n",
    "        # (27, 27, 96)\n",
    "x = BatchNormalization(axis=3, name='bn_conv1')(x)\n",
    "\n",
    "x = Conv2D(256, (5, 5), strides=(4, 4), name='conv2')(x)\n",
    "x = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='pool2')(x)\n",
    "x = BatchNormalization(axis=3, name='bn_conv2')(x)\n",
    "\n",
    "x = Conv2D(512, (3, 3), strides=(1, 1), padding='same', name='conv3')(x)\n",
    "x = Conv2D(1024, (3, 3), strides=(1, 1), padding='same', name='conv4')(x)\n",
    "x = Conv2D(512, (3, 3), strides=(1, 1), padding='same', name='conv5')(x)\n",
    "x = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='pool3')(x)\n",
    "\n",
    "x = Dense(units=4096)(x)\n",
    "x = Dense(units=4096)(x)\n",
    "x = Dense(units=10)(x)\n",
    "x = Activation('softmax')(x)\n",
    "\n",
    "model = Model(inputs=img_input, outputs=x, name='ZFNet Model')\n",
    "\n",
    "optimizer_dicc = {'sgd': optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "                          'rmsprop': optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0),\n",
    "                          'adagrad': optimizers.Adagrad(lr=0.01, epsilon=1e-08, decay=0.0),\n",
    "                          'adadelta': optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0),\n",
    "                          'adam': optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)}\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))\n",
    " \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    " \n",
    "model.save(\"zffnet_mnist_10epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 5 from 3 for 'conv2_7/convolution' (op: 'Conv2D') with input shapes: [?,3,3,96], [5,5,96,256].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    687\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 5 from 3 for 'conv2_7/convolution' (op: 'Conv2D') with input shapes: [?,3,3,96], [5,5,96,256].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-606eb2a01ff3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bn_conv1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'conv2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMaxPool2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pool2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bn_conv2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m             \u001b[1;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    604\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m                 dilation_rate=self.dilation_rate)\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             outputs = K.conv3d(\n",
      "\u001b[1;32mc:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[0;32m   3193\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3194\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3195\u001b[1;33m         data_format=tf_data_format)\n\u001b[0m\u001b[0;32m   3196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3197\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtf_data_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'NHWC'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[1;34m(input, filter, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[0;32m    749\u001b[0m                      \u001b[0mdilation_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdilation_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m                      name=name, data_format=data_format)\n\u001b[1;32m--> 751\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inp, filter)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         name=self.name)\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[0;32m    628\u001b[0m         \u001b[1;34m\"Conv2D\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m         data_format=data_format, name=name)\n\u001b[0m\u001b[0;32m    631\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2956\u001b[0m         op_def=op_def)\n\u001b[0;32m   2957\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2958\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2209\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2210\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32mc:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2158\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2159\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, require_shape_fn)\u001b[0m\n\u001b[0;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m                                   require_shape_fn)\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 5 from 3 for 'conv2_7/convolution' (op: 'Conv2D') with input shapes: [?,3,3,96], [5,5,96,256]."
     ]
    }
   ],
   "source": [
    "input_shape = (28,28,1)\n",
    "img_input = Input(shape=input_shape)\n",
    "        # x = ZeroPadding2D((3, 3))(img_input)\n",
    "x = Conv2D(96, (11, 11), strides=(4, 4), name='conv1')(img_input)\n",
    "        # (55, 55, 96)\n",
    "x = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='pool1')(x)\n",
    "        # (27, 27, 96)\n",
    "x = BatchNormalization(axis=3, name='bn_conv1')(x)\n",
    "\n",
    "x = Conv2D(256, (5, 5), strides=(4, 4), name='conv2')(x)\n",
    "x = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='pool2')(x)\n",
    "x = BatchNormalization(axis=3, name='bn_conv2')(x)\n",
    "\n",
    "x = Conv2D(384, (3, 3), strides=(1, 1), padding=1, name='conv3')(x)\n",
    "x = Conv2D(384, (3, 3), strides=(1, 1), padding=1, name='conv4')(x)\n",
    "x = Conv2D(256, (3, 3), strides=(1, 1), padding=1, name='conv5')(x)\n",
    "x = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same', name='pool3')(x)\n",
    "\n",
    "x = Dense(units=4096)(x)\n",
    "x = Dense(units=4096)(x)\n",
    "x = Dense(units=num_outputs)(x)\n",
    "x = Activation('softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (3, 3), activation=\"relu\", strides=(2, 2), padding=\"valid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  \"\"\"\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "  if sys.path[0] == '':\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "  del sys.path[0]\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\legacy\\layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:42: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:43: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:44: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:45: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:49: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:51: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:56: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:57: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:58: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:59: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:66: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:67: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:68: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:69: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:74: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), padding=\"valid\", kernel_initializer=\"glorot_uniform\")`\n",
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:77: UserWarning: Update your `AveragePooling2D` call to the Keras 2 API: `AveragePooling2D((13, 13), strides=(1, 1), padding=\"same\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\illia\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:83: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 13, 13, 96)   960         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 6, 6, 96)     0           conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 6, 6, 16)     1552        max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 6, 6, 64)     1088        conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 6, 6, 64)     9280        conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_17 (Merge)                (None, 12, 6, 64)    0           conv2d_156[0][0]                 \n",
      "                                                                 conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 12, 6, 64)    0           merge_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 12, 6, 16)    1040        activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 12, 6, 64)    1088        conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 12, 6, 64)    9280        conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_18 (Merge)                (None, 24, 6, 64)    0           conv2d_159[0][0]                 \n",
      "                                                                 conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 24, 6, 64)    0           merge_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 24, 6, 32)    2080        activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 24, 6, 128)   4224        conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 24, 6, 128)   36992       conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_19 (Merge)                (None, 48, 6, 128)   0           conv2d_162[0][0]                 \n",
      "                                                                 conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 48, 6, 128)   0           merge_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 24, 3, 128)   0           activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 24, 3, 32)    4128        max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 24, 3, 128)   4224        conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 24, 3, 128)   36992       conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_20 (Merge)                (None, 48, 3, 128)   0           conv2d_165[0][0]                 \n",
      "                                                                 conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 48, 3, 128)   0           merge_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 48, 3, 48)    6192        activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 48, 3, 192)   9408        conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 48, 3, 192)   83136       conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_21 (Merge)                (None, 96, 3, 192)   0           conv2d_168[0][0]                 \n",
      "                                                                 conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 96, 3, 192)   0           merge_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 96, 3, 48)    9264        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 96, 3, 192)   9408        conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 96, 3, 192)   83136       conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_22 (Merge)                (None, 192, 3, 192)  0           conv2d_171[0][0]                 \n",
      "                                                                 conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 192, 3, 192)  0           merge_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 192, 3, 64)   12352       activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 192, 3, 256)  16640       conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 192, 3, 256)  147712      conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_23 (Merge)                (None, 384, 3, 256)  0           conv2d_174[0][0]                 \n",
      "                                                                 conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 384, 3, 256)  0           merge_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 192, 1, 256)  0           activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 192, 1, 64)   16448       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 192, 1, 256)  16640       conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 192, 1, 256)  147712      conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_24 (Merge)                (None, 384, 1, 256)  0           conv2d_177[0][0]                 \n",
      "                                                                 conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 384, 1, 256)  0           merge_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 384, 1, 256)  0           activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 384, 1, 10)   2570        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 384, 1, 10)   0           conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 3840)         0           average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 10)           38410       flatten_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 711,956\n",
      "Trainable params: 711,956\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 1391s 23ms/step - loss: 0.9373 - acc: 0.6774 - val_loss: 0.1921 - val_acc: 0.9356\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1380s 23ms/step - loss: 0.1208 - acc: 0.9637 - val_loss: 0.0651 - val_acc: 0.9793\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1377s 23ms/step - loss: 0.0756 - acc: 0.9769 - val_loss: 0.0639 - val_acc: 0.9813\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1380s 23ms/step - loss: 0.0586 - acc: 0.9821 - val_loss: 0.0472 - val_acc: 0.9854\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1379s 23ms/step - loss: 0.0465 - acc: 0.9862 - val_loss: 0.0413 - val_acc: 0.9869\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1380s 23ms/step - loss: 0.0387 - acc: 0.9882 - val_loss: 0.0459 - val_acc: 0.9867\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1380s 23ms/step - loss: 0.0325 - acc: 0.9897 - val_loss: 0.0424 - val_acc: 0.9876\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1378s 23ms/step - loss: 0.0269 - acc: 0.9917 - val_loss: 0.0379 - val_acc: 0.9897\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1379s 23ms/step - loss: 0.0240 - acc: 0.9927 - val_loss: 0.0525 - val_acc: 0.9841\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1377s 23ms/step - loss: 0.0206 - acc: 0.9935 - val_loss: 0.0432 - val_acc: 0.9858\n",
      "10000/10000 [==============================] - 71s 7ms/step\n",
      "Test score: 0.0431961057637076\n",
      "Test accuracy: 0.9858\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, merge\n",
    "input_layer = Input(shape=(28, 28,1), name=\"input\")\n",
    "\n",
    "#conv 1\n",
    "conv1 = Convolution2D(96, 3, 3, activation='relu', init='glorot_uniform',subsample=(2,2),border_mode='valid')(input_layer)\n",
    "\n",
    "#maxpool 1\n",
    "maxpool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "\n",
    "#fire 1\n",
    "fire2_squeeze = Convolution2D(16, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(maxpool1)\n",
    "fire2_expand1 = Convolution2D(64, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire2_squeeze)\n",
    "fire2_expand2 = Convolution2D(64, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire2_squeeze)\n",
    "merge1 = merge(inputs=[fire2_expand1, fire2_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire2 = Activation(\"linear\")(merge1)\n",
    "\n",
    "#fire 2\n",
    "fire3_squeeze = Convolution2D(16, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire2)\n",
    "fire3_expand1 = Convolution2D(64, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire3_squeeze)\n",
    "fire3_expand2 = Convolution2D(64, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire3_squeeze)\n",
    "merge2 = merge(inputs=[fire3_expand1, fire3_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire3 = Activation(\"linear\")(merge2)\n",
    "\n",
    "#fire 3\n",
    "fire4_squeeze = Convolution2D(32, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire3)\n",
    "fire4_expand1 = Convolution2D(128, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire4_squeeze)\n",
    "fire4_expand2 = Convolution2D(128, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire4_squeeze)\n",
    "merge3 = merge(inputs=[fire4_expand1, fire4_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire4 = Activation(\"linear\")(merge3)\n",
    "\n",
    "#maxpool 4\n",
    "maxpool4 = MaxPooling2D((2,2))(fire4)\n",
    "\n",
    "#fire 5\n",
    "fire5_squeeze = Convolution2D(32, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(maxpool4)\n",
    "fire5_expand1 = Convolution2D(128, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire5_squeeze)\n",
    "fire5_expand2 = Convolution2D(128, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire5_squeeze)\n",
    "merge5 = merge(inputs=[fire5_expand1, fire5_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire5 = Activation(\"linear\")(merge5)\n",
    "\n",
    "#fire 6\n",
    "fire6_squeeze = Convolution2D(48, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire5)\n",
    "fire6_expand1 = Convolution2D(192, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire6_squeeze)\n",
    "fire6_expand2 = Convolution2D(192, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire6_squeeze)\n",
    "merge6 = merge(inputs=[fire6_expand1, fire6_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire6 = Activation(\"linear\")(merge6)\n",
    "\n",
    "#fire 7\n",
    "fire7_squeeze = Convolution2D(48, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire6)\n",
    "fire7_expand1 = Convolution2D(192, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire7_squeeze)\n",
    "fire7_expand2 = Convolution2D(192, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire7_squeeze)\n",
    "merge7 = merge(inputs=[fire7_expand1, fire7_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire7 =Activation(\"linear\")(merge7)\n",
    "\n",
    "#fire 8\n",
    "fire8_squeeze = Convolution2D(64, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire7)\n",
    "fire8_expand1 = Convolution2D(256, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire8_squeeze)\n",
    "fire8_expand2 = Convolution2D(256, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire8_squeeze)\n",
    "merge8 = merge(inputs=[fire8_expand1, fire8_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire8 = Activation(\"linear\")(merge8)\n",
    "\n",
    "#maxpool 8\n",
    "maxpool8 = MaxPooling2D((2,2))(fire8)\n",
    "\n",
    "#fire 9\n",
    "fire9_squeeze = Convolution2D(64, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(maxpool8)\n",
    "fire9_expand1 = Convolution2D(256, 1, 1, activation='relu', init='glorot_uniform',border_mode='same')(fire9_squeeze)\n",
    "fire9_expand2 = Convolution2D(256, 3, 3, activation='relu', init='glorot_uniform',border_mode='same')(fire9_squeeze)\n",
    "merge8 = merge(inputs=[fire9_expand1, fire9_expand2], mode=\"concat\", concat_axis=1)\n",
    "fire9 = Activation(\"linear\")(merge8)\n",
    "fire9_dropout = Dropout(0.5)(fire9)\n",
    "\n",
    "#conv 10\n",
    "conv10 = Convolution2D(10, 1, 1, init='glorot_uniform',border_mode='valid')(fire9_dropout)\n",
    "\n",
    "#avgpool 1\n",
    "avgpool10 = AveragePooling2D((13,13), strides=(1,1), border_mode='same')(conv10)\n",
    "\n",
    "flatten = Flatten()(avgpool10)\n",
    "\n",
    "softmax = Dense(10, activation=\"softmax\")(flatten)\n",
    "\n",
    "model = Model(input=input_layer, output=softmax)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adadelta', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))\n",
    " \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    " \n",
    "model.save(\"squeezenet_mnist_10epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
